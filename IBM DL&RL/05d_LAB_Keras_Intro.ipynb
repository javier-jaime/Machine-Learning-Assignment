{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-win_amd64.whl (422.6 MB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-py2.py3-none-any.whl (173 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: six~=1.15.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (50.3.1.post20201107)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.32.0-py2.py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: wrapt, termcolor\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19558 sha256=daf2c30a4bc49342b3f682c9a544e03c9cfef0f7dbe6bacfef09cdbe0a279eb6\n",
      "  Stored in directory: c:\\users\\javie\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=5e497c96c1fbc644dfb1d95fce1dce391658eae70bcda889d536dbbf3c3793a7\n",
      "  Stored in directory: c:\\users\\javie\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built wrapt termcolor\n",
      "Installing collected packages: h5py, astunparse, flatbuffers, protobuf, wrapt, keras-nightly, keras-preprocessing, absl-py, opt-einsum, tensorflow-estimator, grpcio, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard-plugin-wit, markdown, tensorboard-data-server, tensorboard, google-pasta, gast, termcolor, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.32.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('data/diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>58</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0.260</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.731</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.678</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>21</td>\n",
       "      <td>168</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.123</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.565</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "334               1                      95              60              18   \n",
       "371               0                     118              64              23   \n",
       "197               3                     107              62              13   \n",
       "325               1                     157              72              21   \n",
       "701               6                     125              78              31   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "334       58  23.9              0.260   22             0  \n",
       "371       89   0.0              1.731   21             0  \n",
       "197       48  22.9              0.678   23             1  \n",
       "325      168  25.6              0.123   24             0  \n",
       "701        0  27.6              0.565   49             1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.821\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.7064 - accuracy: 0.4618 - val_loss: 0.7045 - val_accuracy: 0.4688\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.5069 - val_loss: 0.6969 - val_accuracy: 0.4792\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5312 - val_loss: 0.6900 - val_accuracy: 0.4896\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5694 - val_loss: 0.6838 - val_accuracy: 0.5312\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5851 - val_loss: 0.6783 - val_accuracy: 0.5625\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.6094 - val_loss: 0.6732 - val_accuracy: 0.5990\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6677 - accuracy: 0.6250 - val_loss: 0.6687 - val_accuracy: 0.6094\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6372 - val_loss: 0.6646 - val_accuracy: 0.6510\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6562 - val_loss: 0.6608 - val_accuracy: 0.6667\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6701 - val_loss: 0.6575 - val_accuracy: 0.6875\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6736 - val_loss: 0.6544 - val_accuracy: 0.7031\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6632 - val_loss: 0.6516 - val_accuracy: 0.6875\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6462 - accuracy: 0.6684 - val_loss: 0.6491 - val_accuracy: 0.6823\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6684 - val_loss: 0.6467 - val_accuracy: 0.6615\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6719 - val_loss: 0.6446 - val_accuracy: 0.6510\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.6788 - val_loss: 0.6426 - val_accuracy: 0.6510\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6771 - val_loss: 0.6408 - val_accuracy: 0.6406\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6771 - val_loss: 0.6392 - val_accuracy: 0.6458\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.6753 - val_loss: 0.6376 - val_accuracy: 0.6562\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.6719 - val_loss: 0.6362 - val_accuracy: 0.6615\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6304 - accuracy: 0.6719 - val_loss: 0.6349 - val_accuracy: 0.6562\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.6753 - val_loss: 0.6337 - val_accuracy: 0.6615\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6736 - val_loss: 0.6325 - val_accuracy: 0.6615\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6719 - val_loss: 0.6314 - val_accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6701 - val_loss: 0.6304 - val_accuracy: 0.6615\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6667 - val_loss: 0.6294 - val_accuracy: 0.6562\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6649 - val_loss: 0.6285 - val_accuracy: 0.6562\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6667 - val_loss: 0.6276 - val_accuracy: 0.6562\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.6667 - val_loss: 0.6268 - val_accuracy: 0.6562\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6684 - val_loss: 0.6260 - val_accuracy: 0.6562\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6649 - val_loss: 0.6253 - val_accuracy: 0.6562\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.6667 - val_loss: 0.6245 - val_accuracy: 0.6562\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6684 - val_loss: 0.6238 - val_accuracy: 0.6510\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6667 - val_loss: 0.6231 - val_accuracy: 0.6510\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6165 - accuracy: 0.6649 - val_loss: 0.6225 - val_accuracy: 0.6510\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.6684 - val_loss: 0.6218 - val_accuracy: 0.6510\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6667 - val_loss: 0.6212 - val_accuracy: 0.6510\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.6667 - val_loss: 0.6206 - val_accuracy: 0.6510\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6667 - val_loss: 0.6200 - val_accuracy: 0.6562\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6667 - val_loss: 0.6194 - val_accuracy: 0.6562\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6667 - val_loss: 0.6189 - val_accuracy: 0.6562\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6701 - val_loss: 0.6183 - val_accuracy: 0.6562\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6113 - accuracy: 0.6701 - val_loss: 0.6178 - val_accuracy: 0.6562\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6719 - val_loss: 0.6172 - val_accuracy: 0.6562\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6102 - accuracy: 0.6719 - val_loss: 0.6167 - val_accuracy: 0.6562\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.6719 - val_loss: 0.6162 - val_accuracy: 0.6562\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6736 - val_loss: 0.6156 - val_accuracy: 0.6562\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6086 - accuracy: 0.6719 - val_loss: 0.6151 - val_accuracy: 0.6562\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6080 - accuracy: 0.6736 - val_loss: 0.6146 - val_accuracy: 0.6562\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6736 - val_loss: 0.6141 - val_accuracy: 0.6562\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6069 - accuracy: 0.6736 - val_loss: 0.6136 - val_accuracy: 0.6562\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6736 - val_loss: 0.6131 - val_accuracy: 0.6562\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6059 - accuracy: 0.6736 - val_loss: 0.6126 - val_accuracy: 0.6562\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.6736 - val_loss: 0.6121 - val_accuracy: 0.6562\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6049 - accuracy: 0.6736 - val_loss: 0.6116 - val_accuracy: 0.6562\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6736 - val_loss: 0.6111 - val_accuracy: 0.6562\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.6736 - val_loss: 0.6107 - val_accuracy: 0.6562\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6034 - accuracy: 0.6736 - val_loss: 0.6102 - val_accuracy: 0.6562\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6029 - accuracy: 0.6736 - val_loss: 0.6097 - val_accuracy: 0.6562\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6024 - accuracy: 0.6736 - val_loss: 0.6092 - val_accuracy: 0.6562\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6019 - accuracy: 0.6736 - val_loss: 0.6087 - val_accuracy: 0.6562\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6736 - val_loss: 0.6083 - val_accuracy: 0.6562\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6736 - val_loss: 0.6078 - val_accuracy: 0.6562\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6005 - accuracy: 0.6736 - val_loss: 0.6073 - val_accuracy: 0.6562\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.6736 - val_loss: 0.6069 - val_accuracy: 0.6562\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6736 - val_loss: 0.6064 - val_accuracy: 0.6562\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5990 - accuracy: 0.6736 - val_loss: 0.6059 - val_accuracy: 0.6562\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6736 - val_loss: 0.6055 - val_accuracy: 0.6562\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6736 - val_loss: 0.6050 - val_accuracy: 0.6562\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.6736 - val_loss: 0.6046 - val_accuracy: 0.6562\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.6719 - val_loss: 0.6041 - val_accuracy: 0.6562\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6719 - val_loss: 0.6036 - val_accuracy: 0.6562\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6719 - val_loss: 0.6032 - val_accuracy: 0.6562\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6736 - val_loss: 0.6027 - val_accuracy: 0.6562\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6719 - val_loss: 0.6023 - val_accuracy: 0.6562\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.6719 - val_loss: 0.6018 - val_accuracy: 0.6562\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.6719 - val_loss: 0.6014 - val_accuracy: 0.6562\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.6719 - val_loss: 0.6009 - val_accuracy: 0.6562\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6719 - val_loss: 0.6005 - val_accuracy: 0.6562\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.6701 - val_loss: 0.6000 - val_accuracy: 0.6562\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5926 - accuracy: 0.6701 - val_loss: 0.5996 - val_accuracy: 0.6562\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6701 - val_loss: 0.5991 - val_accuracy: 0.6615\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5917 - accuracy: 0.6701 - val_loss: 0.5987 - val_accuracy: 0.6667\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6719 - val_loss: 0.5983 - val_accuracy: 0.6667\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5908 - accuracy: 0.6684 - val_loss: 0.5978 - val_accuracy: 0.6667\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.6701 - val_loss: 0.5974 - val_accuracy: 0.6719\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.6701 - val_loss: 0.5969 - val_accuracy: 0.6719\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.6701 - val_loss: 0.5965 - val_accuracy: 0.6719\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.6701 - val_loss: 0.5961 - val_accuracy: 0.6719\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6701 - val_loss: 0.5956 - val_accuracy: 0.6719\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6719 - val_loss: 0.5952 - val_accuracy: 0.6719\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.6719 - val_loss: 0.5947 - val_accuracy: 0.6719\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.6736 - val_loss: 0.5943 - val_accuracy: 0.6719\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.6736 - val_loss: 0.5939 - val_accuracy: 0.6771\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.6736 - val_loss: 0.5935 - val_accuracy: 0.6771\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5860 - accuracy: 0.6753 - val_loss: 0.5930 - val_accuracy: 0.6771\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.6736 - val_loss: 0.5926 - val_accuracy: 0.6771\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.6753 - val_loss: 0.5922 - val_accuracy: 0.6771\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5847 - accuracy: 0.6788 - val_loss: 0.5917 - val_accuracy: 0.6771\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.6788 - val_loss: 0.5913 - val_accuracy: 0.6771\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5839 - accuracy: 0.6788 - val_loss: 0.5909 - val_accuracy: 0.6823\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5835 - accuracy: 0.6788 - val_loss: 0.5905 - val_accuracy: 0.6823\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5830 - accuracy: 0.6806 - val_loss: 0.5900 - val_accuracy: 0.6823\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.6806 - val_loss: 0.5896 - val_accuracy: 0.6823\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5822 - accuracy: 0.6806 - val_loss: 0.5892 - val_accuracy: 0.6823\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6806 - val_loss: 0.5888 - val_accuracy: 0.6823\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6806 - val_loss: 0.5884 - val_accuracy: 0.6771\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.6806 - val_loss: 0.5880 - val_accuracy: 0.6771\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6823 - val_loss: 0.5875 - val_accuracy: 0.6771\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5801 - accuracy: 0.6823 - val_loss: 0.5871 - val_accuracy: 0.6771\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.6806 - val_loss: 0.5867 - val_accuracy: 0.6771\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.6840 - val_loss: 0.5863 - val_accuracy: 0.6823\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.6823 - val_loss: 0.5859 - val_accuracy: 0.6823\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5784 - accuracy: 0.6823 - val_loss: 0.5855 - val_accuracy: 0.6823\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.6823 - val_loss: 0.5851 - val_accuracy: 0.6927\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.6823 - val_loss: 0.5847 - val_accuracy: 0.6927\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.6823 - val_loss: 0.5842 - val_accuracy: 0.6979\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.6840 - val_loss: 0.5838 - val_accuracy: 0.6979\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.6823 - val_loss: 0.5834 - val_accuracy: 0.6979\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.6840 - val_loss: 0.5830 - val_accuracy: 0.7031\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.6858 - val_loss: 0.5826 - val_accuracy: 0.7083\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6875 - val_loss: 0.5822 - val_accuracy: 0.7031\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.6875 - val_loss: 0.5818 - val_accuracy: 0.7083\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.6892 - val_loss: 0.5814 - val_accuracy: 0.7083\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.6875 - val_loss: 0.5810 - val_accuracy: 0.7083\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.6875 - val_loss: 0.5806 - val_accuracy: 0.7083\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.6892 - val_loss: 0.5802 - val_accuracy: 0.7083\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.6892 - val_loss: 0.5799 - val_accuracy: 0.7083\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.6892 - val_loss: 0.5795 - val_accuracy: 0.7083\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.6910 - val_loss: 0.5791 - val_accuracy: 0.7083\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.6910 - val_loss: 0.5787 - val_accuracy: 0.7083\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.6927 - val_loss: 0.5783 - val_accuracy: 0.7083\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.6944 - val_loss: 0.5779 - val_accuracy: 0.7083\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.6944 - val_loss: 0.5775 - val_accuracy: 0.7083\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.6944 - val_loss: 0.5771 - val_accuracy: 0.7083\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.6944 - val_loss: 0.5767 - val_accuracy: 0.7135\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5692 - accuracy: 0.6927 - val_loss: 0.5763 - val_accuracy: 0.7135\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.6927 - val_loss: 0.5760 - val_accuracy: 0.7135\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.6944 - val_loss: 0.5756 - val_accuracy: 0.7135\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.6944 - val_loss: 0.5752 - val_accuracy: 0.7135\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.6944 - val_loss: 0.5748 - val_accuracy: 0.7135\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.6927 - val_loss: 0.5744 - val_accuracy: 0.7135\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.6944 - val_loss: 0.5741 - val_accuracy: 0.7135\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.6979 - val_loss: 0.5737 - val_accuracy: 0.7135\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.6962 - val_loss: 0.5733 - val_accuracy: 0.7188\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.6979 - val_loss: 0.5729 - val_accuracy: 0.7188\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.6997 - val_loss: 0.5726 - val_accuracy: 0.7188\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.7031 - val_loss: 0.5722 - val_accuracy: 0.7188\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.7066 - val_loss: 0.5718 - val_accuracy: 0.7188\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7083 - val_loss: 0.5714 - val_accuracy: 0.7188\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7083 - val_loss: 0.5711 - val_accuracy: 0.7188\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.7101 - val_loss: 0.5707 - val_accuracy: 0.7188\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5631 - accuracy: 0.7083 - val_loss: 0.5703 - val_accuracy: 0.7292\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7118 - val_loss: 0.5700 - val_accuracy: 0.7292\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7135 - val_loss: 0.5696 - val_accuracy: 0.7292\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7135 - val_loss: 0.5693 - val_accuracy: 0.7344\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7135 - val_loss: 0.5689 - val_accuracy: 0.7344\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7135 - val_loss: 0.5685 - val_accuracy: 0.7344\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7135 - val_loss: 0.5682 - val_accuracy: 0.7396\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5605 - accuracy: 0.7135 - val_loss: 0.5678 - val_accuracy: 0.7396\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7135 - val_loss: 0.5674 - val_accuracy: 0.7396\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7118 - val_loss: 0.5671 - val_accuracy: 0.7396\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7118 - val_loss: 0.5667 - val_accuracy: 0.7396\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7118 - val_loss: 0.5664 - val_accuracy: 0.7396\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7118 - val_loss: 0.5660 - val_accuracy: 0.7396\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7153 - val_loss: 0.5657 - val_accuracy: 0.7396\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7153 - val_loss: 0.5653 - val_accuracy: 0.7396\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5576 - accuracy: 0.7153 - val_loss: 0.5650 - val_accuracy: 0.7396\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7153 - val_loss: 0.5646 - val_accuracy: 0.7396\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7170 - val_loss: 0.5643 - val_accuracy: 0.7396\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7188 - val_loss: 0.5639 - val_accuracy: 0.7396\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7188 - val_loss: 0.5636 - val_accuracy: 0.7448\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7188 - val_loss: 0.5632 - val_accuracy: 0.7448\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7188 - val_loss: 0.5629 - val_accuracy: 0.7448\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7205 - val_loss: 0.5625 - val_accuracy: 0.7448\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7222 - val_loss: 0.5622 - val_accuracy: 0.7448\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5544 - accuracy: 0.7222 - val_loss: 0.5619 - val_accuracy: 0.7448\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7222 - val_loss: 0.5615 - val_accuracy: 0.7448\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.7222 - val_loss: 0.5612 - val_accuracy: 0.7448\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5534 - accuracy: 0.7222 - val_loss: 0.5608 - val_accuracy: 0.7448\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5531 - accuracy: 0.7222 - val_loss: 0.5605 - val_accuracy: 0.7448\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7222 - val_loss: 0.5602 - val_accuracy: 0.7448\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7222 - val_loss: 0.5598 - val_accuracy: 0.7552\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7222 - val_loss: 0.5595 - val_accuracy: 0.7552\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.7222 - val_loss: 0.5592 - val_accuracy: 0.7552\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7240 - val_loss: 0.5588 - val_accuracy: 0.7552\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7240 - val_loss: 0.5585 - val_accuracy: 0.7552\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5507 - accuracy: 0.7240 - val_loss: 0.5582 - val_accuracy: 0.7552\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7240 - val_loss: 0.5579 - val_accuracy: 0.7552\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.7240 - val_loss: 0.5575 - val_accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5496 - accuracy: 0.7240 - val_loss: 0.5572 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7240 - val_loss: 0.5569 - val_accuracy: 0.7500\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.7240 - val_loss: 0.5566 - val_accuracy: 0.7500\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7274 - val_loss: 0.5562 - val_accuracy: 0.7500\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7274 - val_loss: 0.5559 - val_accuracy: 0.7500\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7274 - val_loss: 0.5556 - val_accuracy: 0.7500\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7257 - val_loss: 0.5553 - val_accuracy: 0.7500\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5473 - accuracy: 0.7257 - val_loss: 0.5550 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.7257 - val_loss: 0.5546 - val_accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7274 - val_loss: 0.5543 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37276226],\n",
       "       [0.51888674],\n",
       "       [0.31393826],\n",
       "       [0.34256965],\n",
       "       [0.23000011],\n",
       "       [0.4749729 ],\n",
       "       [0.22691092],\n",
       "       [0.3517726 ],\n",
       "       [0.6092871 ],\n",
       "       [0.3703044 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.750\n",
      "roc-auc is 0.797\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ee17276eb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7274 - val_loss: 0.5540 - val_accuracy: 0.7500\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5460 - accuracy: 0.7274 - val_loss: 0.5537 - val_accuracy: 0.7500\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5457 - accuracy: 0.7274 - val_loss: 0.5534 - val_accuracy: 0.7500\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7274 - val_loss: 0.5531 - val_accuracy: 0.7500\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7274 - val_loss: 0.5528 - val_accuracy: 0.7500\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7274 - val_loss: 0.5525 - val_accuracy: 0.7500\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7274 - val_loss: 0.5522 - val_accuracy: 0.7500\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7274 - val_loss: 0.5518 - val_accuracy: 0.7500\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7274 - val_loss: 0.5515 - val_accuracy: 0.7500\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7274 - val_loss: 0.5512 - val_accuracy: 0.7500\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5431 - accuracy: 0.7292 - val_loss: 0.5509 - val_accuracy: 0.7500\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7292 - val_loss: 0.5506 - val_accuracy: 0.7552\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7292 - val_loss: 0.5503 - val_accuracy: 0.7552\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7274 - val_loss: 0.5500 - val_accuracy: 0.7552\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7274 - val_loss: 0.5497 - val_accuracy: 0.7552\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7257 - val_loss: 0.5494 - val_accuracy: 0.7552\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7257 - val_loss: 0.5491 - val_accuracy: 0.7552\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7292 - val_loss: 0.5488 - val_accuracy: 0.7552\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7309 - val_loss: 0.5485 - val_accuracy: 0.7552\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.7292 - val_loss: 0.5482 - val_accuracy: 0.7552\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5400 - accuracy: 0.7309 - val_loss: 0.5480 - val_accuracy: 0.7552\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7309 - val_loss: 0.5477 - val_accuracy: 0.7552\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7309 - val_loss: 0.5474 - val_accuracy: 0.7604\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7309 - val_loss: 0.5471 - val_accuracy: 0.7604\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7274 - val_loss: 0.5468 - val_accuracy: 0.7656\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.7274 - val_loss: 0.5465 - val_accuracy: 0.7656\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.7274 - val_loss: 0.5462 - val_accuracy: 0.7656\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7274 - val_loss: 0.5459 - val_accuracy: 0.7656\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7274 - val_loss: 0.5457 - val_accuracy: 0.7708\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7274 - val_loss: 0.5454 - val_accuracy: 0.7708\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7257 - val_loss: 0.5451 - val_accuracy: 0.7708\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7257 - val_loss: 0.5448 - val_accuracy: 0.7656\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7257 - val_loss: 0.5445 - val_accuracy: 0.7604\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7274 - val_loss: 0.5442 - val_accuracy: 0.7604\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7292 - val_loss: 0.5440 - val_accuracy: 0.7604\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7274 - val_loss: 0.5437 - val_accuracy: 0.7604\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7292 - val_loss: 0.5434 - val_accuracy: 0.7604\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7274 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7292 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7292 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7309 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7309 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.7309 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.7309 - val_loss: 0.5415 - val_accuracy: 0.7552\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.7326 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7326 - val_loss: 0.5410 - val_accuracy: 0.7552\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7326 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.7326 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7326 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7344 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5312 - accuracy: 0.7361 - val_loss: 0.5397 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.7361 - val_loss: 0.5394 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 0.7378 - val_loss: 0.5391 - val_accuracy: 0.7552\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.7378 - val_loss: 0.5389 - val_accuracy: 0.7552\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.7396 - val_loss: 0.5386 - val_accuracy: 0.7552\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7361 - val_loss: 0.5384 - val_accuracy: 0.7552\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7413 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.7396 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7413 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.7396 - val_loss: 0.5374 - val_accuracy: 0.7552\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7396 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5282 - accuracy: 0.7413 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7413 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7431 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7431 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7448 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7448 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7448 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.7465 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7465 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7465 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7465 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7448 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7448 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7448 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7448 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.7448 - val_loss: 0.5332 - val_accuracy: 0.7552\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7448 - val_loss: 0.5330 - val_accuracy: 0.7552\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7448 - val_loss: 0.5328 - val_accuracy: 0.7552\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7448 - val_loss: 0.5325 - val_accuracy: 0.7552\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7448 - val_loss: 0.5323 - val_accuracy: 0.7552\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7448 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7448 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.7431 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7448 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7431 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7431 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7431 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7448 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7431 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7448 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7500 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7500 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7500 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5198 - accuracy: 0.7500 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7500 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.7500 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7500 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7500 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7500 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7500 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7500 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7500 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7500 - val_loss: 0.5272 - val_accuracy: 0.7448\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7517 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7500 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7517 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7517 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7517 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7517 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7517 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7517 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7517 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7517 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7535 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.7535 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.7535 - val_loss: 0.5246 - val_accuracy: 0.7448\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7535 - val_loss: 0.5244 - val_accuracy: 0.7448\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7535 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.7535 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7535 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7535 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7552 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.7535 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.7517 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7517 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7517 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7517 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7517 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7517 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7517 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7535 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7517 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7535 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7517 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7517 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7517 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7517 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7517 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7517 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7552 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7552 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7552 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7552 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7552 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7552 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7552 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7552 - val_loss: 0.5180 - val_accuracy: 0.7448\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7552 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7552 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7552 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7552 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7552 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7552 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7569 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7569 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7569 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7552 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7569 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7535 - val_loss: 0.5161 - val_accuracy: 0.7396\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7569 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7535 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7535 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7535 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.7569 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7535 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7535 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5148 - val_accuracy: 0.7344\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5035 - accuracy: 0.7535 - val_loss: 0.5147 - val_accuracy: 0.7344\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7535 - val_loss: 0.5145 - val_accuracy: 0.7344\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7535 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7552 - val_loss: 0.5142 - val_accuracy: 0.7396\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7535 - val_loss: 0.5140 - val_accuracy: 0.7396\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7552 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7569 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7569 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7552 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7569 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7587 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7587 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7604 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7604 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7604 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7604 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7604 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7604 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7604 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.7604 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7604 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7604 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7604 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7604 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.7604 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.56 - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7604 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7604 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.7604 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7604 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7656 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7622 - val_loss: 0.5104 - val_accuracy: 0.7396\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7656 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7656 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7656 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7656 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.7639 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7656 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7639 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7639 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7639 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7639 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7639 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7639 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7639 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7622 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7622 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7622 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7622 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7622 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7622 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7622 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7622 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7622 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7622 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7622 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7622 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7622 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7622 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7622 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7622 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7622 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7622 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7622 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7622 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7622 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7622 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7622 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7622 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7622 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7622 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7622 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7622 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7622 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7622 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7622 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7622 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7622 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.7622 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7622 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7622 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7622 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7622 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7622 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7622 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.7622 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7622 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.7622 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7622 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7622 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7622 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.7622 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7622 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7622 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7622 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7622 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7622 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7622 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7622 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7622 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7622 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7604 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7604 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7604 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7622 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7604 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7604 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7622 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7604 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7639 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7622 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7622 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7639 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7639 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7639 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7639 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7639 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7639 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7656 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7656 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7656 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7656 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7656 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7656 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7639 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7639 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7639 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7639 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7656 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7639 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7639 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7639 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7639 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7639 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7639 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7639 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7639 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7639 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7639 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7639 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7639 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7639 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7639 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7639 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7639 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7639 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7639 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7639 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7639 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7639 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7622 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7622 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7622 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7622 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7622 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7622 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7639 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7639 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7604 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7622 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7639 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7639 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7604 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7639 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7639 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7622 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7639 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7639 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7639 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7656 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7639 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7656 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7639 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7639 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7639 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7639 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7639 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7639 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7639 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7639 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7656 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7656 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7656 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7656 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7656 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7656 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7656 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7656 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7691 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7691 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7691 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7691 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.4941 - val_accuracy: 0.7500\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7691 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7691 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7691 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7691 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7691 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7691 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7691 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7691 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7674 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.78 - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7674 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7674 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7674 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7674 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7674 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7674 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7674 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7674 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7674 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7674 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7674 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7656 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7674 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7674 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7674 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7674 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7674 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7656 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7656 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7656 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7656 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7656 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7656 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7639 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7656 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7656 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7656 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7639 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7639 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7639 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7639 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7639 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7639 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7639 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7656 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7639 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7656 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.7639 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7656 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7656 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.7656 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.7656 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7656 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7656 - val_loss: 0.4908 - val_accuracy: 0.7500\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7656 - val_loss: 0.4908 - val_accuracy: 0.7500\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7656 - val_loss: 0.4907 - val_accuracy: 0.7500\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7656 - val_loss: 0.4907 - val_accuracy: 0.7500\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7656 - val_loss: 0.4907 - val_accuracy: 0.7500\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7656 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7656 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7656 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7656 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7656 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7656 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7656 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7656 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7656 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7656 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7656 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7656 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7656 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7656 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7656 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7656 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7656 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7656 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7656 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7656 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7656 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7639 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7639 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7639 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7639 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7639 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7639 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7639 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7639 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7639 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7639 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7639 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7639 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7639 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7639 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7639 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7639 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7639 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7639 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7639 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7639 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7639 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7639 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7639 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7639 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7639 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7639 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7639 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7639 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7639 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7639 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7639 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7639 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7639 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7639 - val_loss: 0.4890 - val_accuracy: 0.7552\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7639 - val_loss: 0.4889 - val_accuracy: 0.7552\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7639 - val_loss: 0.4889 - val_accuracy: 0.7552\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7639 - val_loss: 0.4889 - val_accuracy: 0.7552\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7639 - val_loss: 0.4888 - val_accuracy: 0.7552\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7639 - val_loss: 0.4888 - val_accuracy: 0.7552\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7639 - val_loss: 0.4888 - val_accuracy: 0.7552\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7639 - val_loss: 0.4888 - val_accuracy: 0.7552\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7639 - val_loss: 0.4887 - val_accuracy: 0.7552\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7639 - val_loss: 0.4887 - val_accuracy: 0.7552\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7639 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7639 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7639 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7639 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7639 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7639 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7639 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7639 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7639 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7639 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7639 - val_loss: 0.4884 - val_accuracy: 0.7500\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7639 - val_loss: 0.4884 - val_accuracy: 0.7500\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7639 - val_loss: 0.4884 - val_accuracy: 0.7500\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7639 - val_loss: 0.4884 - val_accuracy: 0.7500\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7639 - val_loss: 0.4883 - val_accuracy: 0.7500\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7639 - val_loss: 0.4883 - val_accuracy: 0.7500\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7639 - val_loss: 0.4883 - val_accuracy: 0.7500\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7639 - val_loss: 0.4883 - val_accuracy: 0.7500\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7639 - val_loss: 0.4883 - val_accuracy: 0.7500\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7639 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7639 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7639 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7656 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7639 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7639 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7656 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7656 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7656 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7656 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7656 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7656 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7656 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7656 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7674 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7656 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7674 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7674 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7674 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7656 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7674 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7656 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7674 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7656 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7622 - val_loss: 0.4877 - val_accuracy: 0.7500\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7656 - val_loss: 0.4877 - val_accuracy: 0.7500\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7656 - val_loss: 0.4877 - val_accuracy: 0.7500\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7656 - val_loss: 0.4877 - val_accuracy: 0.7500\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7656 - val_loss: 0.4876 - val_accuracy: 0.7500\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7622 - val_loss: 0.4876 - val_accuracy: 0.7500\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7656 - val_loss: 0.4876 - val_accuracy: 0.7500\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7656 - val_loss: 0.4876 - val_accuracy: 0.7500\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7674 - val_loss: 0.4876 - val_accuracy: 0.7500\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7656 - val_loss: 0.4875 - val_accuracy: 0.7500\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7656 - val_loss: 0.4875 - val_accuracy: 0.7500\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7674 - val_loss: 0.4875 - val_accuracy: 0.7500\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7656 - val_loss: 0.4875 - val_accuracy: 0.7500\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7656 - val_loss: 0.4875 - val_accuracy: 0.7500\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7674 - val_loss: 0.4874 - val_accuracy: 0.7500\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7674 - val_loss: 0.4874 - val_accuracy: 0.7500\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7656 - val_loss: 0.4874 - val_accuracy: 0.7500\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7656 - val_loss: 0.4874 - val_accuracy: 0.7500\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7674 - val_loss: 0.4874 - val_accuracy: 0.7500\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7674 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7656 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7656 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7656 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7656 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7656 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7656 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7656 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7656 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7656 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7656 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7656 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7656 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7656 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7656 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7656 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7656 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7656 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7656 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7656 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7656 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7656 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7656 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7656 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7656 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7656 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7656 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7656 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7656 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7656 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7656 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7656 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7674 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7674 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7674 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7691 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7674 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7691 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7691 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7691 - val_loss: 0.4865 - val_accuracy: 0.7448\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7691 - val_loss: 0.4864 - val_accuracy: 0.7448\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7691 - val_loss: 0.4864 - val_accuracy: 0.7448\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7691 - val_loss: 0.4864 - val_accuracy: 0.7448\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7691 - val_loss: 0.4864 - val_accuracy: 0.7448\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.4864 - val_accuracy: 0.7448\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7691 - val_loss: 0.4864 - val_accuracy: 0.7448\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7691 - val_loss: 0.4864 - val_accuracy: 0.7448\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7691 - val_loss: 0.4864 - val_accuracy: 0.7448\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7708 - val_loss: 0.4863 - val_accuracy: 0.7448\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7708 - val_loss: 0.4863 - val_accuracy: 0.7448\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7448\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7448\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7448\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7448\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7448\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7691 - val_loss: 0.4863 - val_accuracy: 0.7448\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7448\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7448\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7448\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7448\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7448\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7448\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7448\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7448\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.4862 - val_accuracy: 0.7448\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7448\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7448\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7448\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7448\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7448\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7448\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.4861 - val_accuracy: 0.7448\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7448\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7448\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7448\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7448\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7448\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7448\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7448\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7448\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7448\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7448\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7448\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7448\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7448\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7448\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7708 - val_loss: 0.4857 - val_accuracy: 0.7448\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7448\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7708 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7708 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7708 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7708 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7708 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4855 - val_accuracy: 0.7448\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7448\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7448\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7448\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7448\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7448\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.84 - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4849 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ee172b5a00>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6976 - accuracy: 0.6007 - val_loss: 0.7005 - val_accuracy: 0.5781\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.6076 - val_loss: 0.6978 - val_accuracy: 0.5833\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.6111 - val_loss: 0.6952 - val_accuracy: 0.5833\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.6146 - val_loss: 0.6926 - val_accuracy: 0.5885\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.6215 - val_loss: 0.6901 - val_accuracy: 0.5885\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.6233 - val_loss: 0.6875 - val_accuracy: 0.5885\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.6215 - val_loss: 0.6851 - val_accuracy: 0.5938\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6215 - val_loss: 0.6826 - val_accuracy: 0.5990\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.6250 - val_loss: 0.6803 - val_accuracy: 0.5885\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.6319 - val_loss: 0.6779 - val_accuracy: 0.5885\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6687 - accuracy: 0.6337 - val_loss: 0.6756 - val_accuracy: 0.5938\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.6354 - val_loss: 0.6733 - val_accuracy: 0.5990\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.6354 - val_loss: 0.6710 - val_accuracy: 0.6042\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6337 - val_loss: 0.6688 - val_accuracy: 0.6042\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6354 - val_loss: 0.6666 - val_accuracy: 0.6042\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6389 - val_loss: 0.6645 - val_accuracy: 0.6042\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6424 - val_loss: 0.6624 - val_accuracy: 0.6094\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6441 - val_loss: 0.6604 - val_accuracy: 0.6198\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6441 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6441 - val_loss: 0.6563 - val_accuracy: 0.6354\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6458 - val_loss: 0.6544 - val_accuracy: 0.6302\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6458 - val_loss: 0.6525 - val_accuracy: 0.6302\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6493 - val_loss: 0.6506 - val_accuracy: 0.6302\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.6528 - val_loss: 0.6488 - val_accuracy: 0.6302\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6545 - val_loss: 0.6469 - val_accuracy: 0.6354\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.6528 - val_loss: 0.6451 - val_accuracy: 0.6354\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6545 - val_loss: 0.6433 - val_accuracy: 0.6354\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6528 - val_loss: 0.6416 - val_accuracy: 0.6354\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.6528 - val_loss: 0.6399 - val_accuracy: 0.6354\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.6580 - val_loss: 0.6382 - val_accuracy: 0.6354\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6580 - val_loss: 0.6366 - val_accuracy: 0.6354\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6181 - accuracy: 0.6562 - val_loss: 0.6349 - val_accuracy: 0.6354\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6160 - accuracy: 0.6562 - val_loss: 0.6333 - val_accuracy: 0.6354\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.6580 - val_loss: 0.6317 - val_accuracy: 0.6354\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.6562 - val_loss: 0.6302 - val_accuracy: 0.6354\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6562 - val_loss: 0.6286 - val_accuracy: 0.6354\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.6545 - val_loss: 0.6271 - val_accuracy: 0.6354\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6057 - accuracy: 0.6545 - val_loss: 0.6256 - val_accuracy: 0.6354\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6038 - accuracy: 0.6545 - val_loss: 0.6241 - val_accuracy: 0.6354\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6019 - accuracy: 0.6562 - val_loss: 0.6227 - val_accuracy: 0.6354\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.6562 - val_loss: 0.6213 - val_accuracy: 0.6354\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6562 - val_loss: 0.6200 - val_accuracy: 0.6354\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.6545 - val_loss: 0.6186 - val_accuracy: 0.6406\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.6545 - val_loss: 0.6173 - val_accuracy: 0.6406\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.6545 - val_loss: 0.6161 - val_accuracy: 0.6406\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5908 - accuracy: 0.6545 - val_loss: 0.6148 - val_accuracy: 0.6406\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.6545 - val_loss: 0.6136 - val_accuracy: 0.6406\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.6545 - val_loss: 0.6124 - val_accuracy: 0.6406\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6545 - val_loss: 0.6112 - val_accuracy: 0.6406\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6545 - val_loss: 0.6101 - val_accuracy: 0.6406\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.6545 - val_loss: 0.6089 - val_accuracy: 0.6406\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.6545 - val_loss: 0.6078 - val_accuracy: 0.6406\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.6545 - val_loss: 0.6067 - val_accuracy: 0.6406\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.6545 - val_loss: 0.6056 - val_accuracy: 0.6406\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.6545 - val_loss: 0.6046 - val_accuracy: 0.6406\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.6545 - val_loss: 0.6036 - val_accuracy: 0.6406\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.6545 - val_loss: 0.6025 - val_accuracy: 0.6406\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.6545 - val_loss: 0.6015 - val_accuracy: 0.6406\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.6545 - val_loss: 0.6005 - val_accuracy: 0.6406\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.6545 - val_loss: 0.5995 - val_accuracy: 0.6406\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.6545 - val_loss: 0.5986 - val_accuracy: 0.6406\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.6545 - val_loss: 0.5977 - val_accuracy: 0.6406\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.6545 - val_loss: 0.5968 - val_accuracy: 0.6406\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.6545 - val_loss: 0.5959 - val_accuracy: 0.6406\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.6545 - val_loss: 0.5950 - val_accuracy: 0.6406\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.6545 - val_loss: 0.5942 - val_accuracy: 0.6406\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.6545 - val_loss: 0.5933 - val_accuracy: 0.6406\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.6545 - val_loss: 0.5926 - val_accuracy: 0.6406\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.6545 - val_loss: 0.5918 - val_accuracy: 0.6406\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.6545 - val_loss: 0.5910 - val_accuracy: 0.6406\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.6545 - val_loss: 0.5903 - val_accuracy: 0.6406\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.6545 - val_loss: 0.5896 - val_accuracy: 0.6406\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.6545 - val_loss: 0.5888 - val_accuracy: 0.6406\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.6545 - val_loss: 0.5881 - val_accuracy: 0.6406\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.6545 - val_loss: 0.5874 - val_accuracy: 0.6406\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.6545 - val_loss: 0.5868 - val_accuracy: 0.6406\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.6545 - val_loss: 0.5861 - val_accuracy: 0.6406\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.6545 - val_loss: 0.5855 - val_accuracy: 0.6406\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.6545 - val_loss: 0.5848 - val_accuracy: 0.6406\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.6545 - val_loss: 0.5842 - val_accuracy: 0.6406\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.6545 - val_loss: 0.5836 - val_accuracy: 0.6406\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.6545 - val_loss: 0.5830 - val_accuracy: 0.6406\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5437 - accuracy: 0.6545 - val_loss: 0.5825 - val_accuracy: 0.6406\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.6545 - val_loss: 0.5819 - val_accuracy: 0.6406\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5420 - accuracy: 0.6545 - val_loss: 0.5813 - val_accuracy: 0.6406\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.6545 - val_loss: 0.5808 - val_accuracy: 0.6406\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.6545 - val_loss: 0.5803 - val_accuracy: 0.6406\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.6545 - val_loss: 0.5797 - val_accuracy: 0.6406\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.6545 - val_loss: 0.5792 - val_accuracy: 0.6406\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.6545 - val_loss: 0.5787 - val_accuracy: 0.6406\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.6545 - val_loss: 0.5782 - val_accuracy: 0.6406\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.6545 - val_loss: 0.5777 - val_accuracy: 0.6406\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.6545 - val_loss: 0.5773 - val_accuracy: 0.6406\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.6545 - val_loss: 0.5768 - val_accuracy: 0.6406\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.6545 - val_loss: 0.5763 - val_accuracy: 0.6406\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.6545 - val_loss: 0.5759 - val_accuracy: 0.6406\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.6545 - val_loss: 0.5754 - val_accuracy: 0.6406\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.6545 - val_loss: 0.5750 - val_accuracy: 0.6406\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.6545 - val_loss: 0.5745 - val_accuracy: 0.6406\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.6545 - val_loss: 0.5741 - val_accuracy: 0.6406\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.6545 - val_loss: 0.5737 - val_accuracy: 0.6406\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.6545 - val_loss: 0.5733 - val_accuracy: 0.6406\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.6545 - val_loss: 0.5729 - val_accuracy: 0.6406\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.6545 - val_loss: 0.5725 - val_accuracy: 0.6406\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.6545 - val_loss: 0.5721 - val_accuracy: 0.6406\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.6545 - val_loss: 0.5717 - val_accuracy: 0.6406\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.6545 - val_loss: 0.5714 - val_accuracy: 0.6406\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.6545 - val_loss: 0.5710 - val_accuracy: 0.6406\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.6545 - val_loss: 0.5707 - val_accuracy: 0.6406\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.6545 - val_loss: 0.5704 - val_accuracy: 0.6406\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.6545 - val_loss: 0.5700 - val_accuracy: 0.6406\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.6545 - val_loss: 0.5697 - val_accuracy: 0.6406\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.6545 - val_loss: 0.5694 - val_accuracy: 0.6406\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.6545 - val_loss: 0.5692 - val_accuracy: 0.6406\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5221 - accuracy: 0.6545 - val_loss: 0.5689 - val_accuracy: 0.6406\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.6545 - val_loss: 0.5686 - val_accuracy: 0.6406\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.6545 - val_loss: 0.5683 - val_accuracy: 0.6406\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.6545 - val_loss: 0.5681 - val_accuracy: 0.6406\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.6545 - val_loss: 0.5678 - val_accuracy: 0.6406\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.6545 - val_loss: 0.5676 - val_accuracy: 0.6406\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.6545 - val_loss: 0.5673 - val_accuracy: 0.6406\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.6545 - val_loss: 0.5671 - val_accuracy: 0.6406\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.6545 - val_loss: 0.5668 - val_accuracy: 0.6406\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.6545 - val_loss: 0.5666 - val_accuracy: 0.6406\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.6545 - val_loss: 0.5663 - val_accuracy: 0.6406\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.6545 - val_loss: 0.5661 - val_accuracy: 0.6406\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.6545 - val_loss: 0.5659 - val_accuracy: 0.6406\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.6545 - val_loss: 0.5657 - val_accuracy: 0.6406\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5153 - accuracy: 0.6545 - val_loss: 0.5654 - val_accuracy: 0.6406\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.6545 - val_loss: 0.5652 - val_accuracy: 0.6406\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.6545 - val_loss: 0.5650 - val_accuracy: 0.6406\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.6545 - val_loss: 0.5648 - val_accuracy: 0.6406\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.6545 - val_loss: 0.5646 - val_accuracy: 0.6406\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.6545 - val_loss: 0.5644 - val_accuracy: 0.6406\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.6545 - val_loss: 0.5642 - val_accuracy: 0.6406\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.6545 - val_loss: 0.5640 - val_accuracy: 0.6406\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.6545 - val_loss: 0.5638 - val_accuracy: 0.6406\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.6545 - val_loss: 0.5637 - val_accuracy: 0.6406\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.6615 - val_loss: 0.5635 - val_accuracy: 0.6875\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.6788 - val_loss: 0.5633 - val_accuracy: 0.6927\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.6788 - val_loss: 0.5631 - val_accuracy: 0.6979\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.6771 - val_loss: 0.5629 - val_accuracy: 0.7031\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.6771 - val_loss: 0.5628 - val_accuracy: 0.6979\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.6771 - val_loss: 0.5626 - val_accuracy: 0.7031\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.6771 - val_loss: 0.5625 - val_accuracy: 0.7031\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.6788 - val_loss: 0.5624 - val_accuracy: 0.7083\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.6806 - val_loss: 0.5622 - val_accuracy: 0.7083\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.6806 - val_loss: 0.5621 - val_accuracy: 0.7083\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.6840 - val_loss: 0.5620 - val_accuracy: 0.7188\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.6858 - val_loss: 0.5619 - val_accuracy: 0.7135\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.6875 - val_loss: 0.5618 - val_accuracy: 0.7135\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.6910 - val_loss: 0.5617 - val_accuracy: 0.7135\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.6927 - val_loss: 0.5616 - val_accuracy: 0.7135\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.6962 - val_loss: 0.5615 - val_accuracy: 0.7135\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.6979 - val_loss: 0.5614 - val_accuracy: 0.7135\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7014 - val_loss: 0.5613 - val_accuracy: 0.7083\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7031 - val_loss: 0.5612 - val_accuracy: 0.7083\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7049 - val_loss: 0.5611 - val_accuracy: 0.7083\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7066 - val_loss: 0.5610 - val_accuracy: 0.7135\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7083 - val_loss: 0.5609 - val_accuracy: 0.7135\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7153 - val_loss: 0.5608 - val_accuracy: 0.7083\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7188 - val_loss: 0.5607 - val_accuracy: 0.7031\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7205 - val_loss: 0.5606 - val_accuracy: 0.7031\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7222 - val_loss: 0.5606 - val_accuracy: 0.6979\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7222 - val_loss: 0.5605 - val_accuracy: 0.6979\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7222 - val_loss: 0.5604 - val_accuracy: 0.6979\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7222 - val_loss: 0.5603 - val_accuracy: 0.6979\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7222 - val_loss: 0.5603 - val_accuracy: 0.6979\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7222 - val_loss: 0.5602 - val_accuracy: 0.6979\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.7188 - val_loss: 0.5601 - val_accuracy: 0.6979\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7153 - val_loss: 0.5600 - val_accuracy: 0.6979\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.7170 - val_loss: 0.5600 - val_accuracy: 0.7031\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7188 - val_loss: 0.5599 - val_accuracy: 0.6979\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.7188 - val_loss: 0.5598 - val_accuracy: 0.6979\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7188 - val_loss: 0.5598 - val_accuracy: 0.6979\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7205 - val_loss: 0.5597 - val_accuracy: 0.6979\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7205 - val_loss: 0.5596 - val_accuracy: 0.7031\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7222 - val_loss: 0.5596 - val_accuracy: 0.7031\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7240 - val_loss: 0.5595 - val_accuracy: 0.6875\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7240 - val_loss: 0.5594 - val_accuracy: 0.6875\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7205 - val_loss: 0.5594 - val_accuracy: 0.6823\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7188 - val_loss: 0.5593 - val_accuracy: 0.6823\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7205 - val_loss: 0.5592 - val_accuracy: 0.6875\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7222 - val_loss: 0.5592 - val_accuracy: 0.6875\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7240 - val_loss: 0.5591 - val_accuracy: 0.6875\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7257 - val_loss: 0.5590 - val_accuracy: 0.6875\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7274 - val_loss: 0.5590 - val_accuracy: 0.6875\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7292 - val_loss: 0.5589 - val_accuracy: 0.6875\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7292 - val_loss: 0.5588 - val_accuracy: 0.6823\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7274 - val_loss: 0.5588 - val_accuracy: 0.6823\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7309 - val_loss: 0.5587 - val_accuracy: 0.6823\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7326 - val_loss: 0.5586 - val_accuracy: 0.6823\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7326 - val_loss: 0.5586 - val_accuracy: 0.6823\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7344 - val_loss: 0.5585 - val_accuracy: 0.6771\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7326 - val_loss: 0.5585 - val_accuracy: 0.6771\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7309 - val_loss: 0.5584 - val_accuracy: 0.6771\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7274 - val_loss: 0.5584 - val_accuracy: 0.6771\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7240 - val_loss: 0.5583 - val_accuracy: 0.6823\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7240 - val_loss: 0.5583 - val_accuracy: 0.6875\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7240 - val_loss: 0.5582 - val_accuracy: 0.6823\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7222 - val_loss: 0.5581 - val_accuracy: 0.6875\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7222 - val_loss: 0.5581 - val_accuracy: 0.6875\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7222 - val_loss: 0.5580 - val_accuracy: 0.6875\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7222 - val_loss: 0.5580 - val_accuracy: 0.6875\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7257 - val_loss: 0.5579 - val_accuracy: 0.6875\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7257 - val_loss: 0.5579 - val_accuracy: 0.6823\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7257 - val_loss: 0.5578 - val_accuracy: 0.6823\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7257 - val_loss: 0.5578 - val_accuracy: 0.6823\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7274 - val_loss: 0.5578 - val_accuracy: 0.6823\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7292 - val_loss: 0.5577 - val_accuracy: 0.6823\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7309 - val_loss: 0.5577 - val_accuracy: 0.6823\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7326 - val_loss: 0.5576 - val_accuracy: 0.6823\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7326 - val_loss: 0.5576 - val_accuracy: 0.6823\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7361 - val_loss: 0.5576 - val_accuracy: 0.6823\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7378 - val_loss: 0.5575 - val_accuracy: 0.6823\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7396 - val_loss: 0.5575 - val_accuracy: 0.6823\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.7413 - val_loss: 0.5574 - val_accuracy: 0.6927\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7431 - val_loss: 0.5574 - val_accuracy: 0.6979\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.7431 - val_loss: 0.5574 - val_accuracy: 0.6979\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7413 - val_loss: 0.5573 - val_accuracy: 0.6979\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.7431 - val_loss: 0.5573 - val_accuracy: 0.6979\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7413 - val_loss: 0.5573 - val_accuracy: 0.6979\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7413 - val_loss: 0.5572 - val_accuracy: 0.6979\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7413 - val_loss: 0.5572 - val_accuracy: 0.6979\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7431 - val_loss: 0.5571 - val_accuracy: 0.6979\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7431 - val_loss: 0.5571 - val_accuracy: 0.6979\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7396 - val_loss: 0.5571 - val_accuracy: 0.6927\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7396 - val_loss: 0.5570 - val_accuracy: 0.6927\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7396 - val_loss: 0.5570 - val_accuracy: 0.6927\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7431 - val_loss: 0.5570 - val_accuracy: 0.6927\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7431 - val_loss: 0.5569 - val_accuracy: 0.6875\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7431 - val_loss: 0.5569 - val_accuracy: 0.6875\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7431 - val_loss: 0.5569 - val_accuracy: 0.6875\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7431 - val_loss: 0.5569 - val_accuracy: 0.6875\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7413 - val_loss: 0.5568 - val_accuracy: 0.6875\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7413 - val_loss: 0.5568 - val_accuracy: 0.6875\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7413 - val_loss: 0.5567 - val_accuracy: 0.6875\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7431 - val_loss: 0.5567 - val_accuracy: 0.6875\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7431 - val_loss: 0.5567 - val_accuracy: 0.6875\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7431 - val_loss: 0.5566 - val_accuracy: 0.6875\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7431 - val_loss: 0.5566 - val_accuracy: 0.6875\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7431 - val_loss: 0.5566 - val_accuracy: 0.6875\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7431 - val_loss: 0.5565 - val_accuracy: 0.6875\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7431 - val_loss: 0.5565 - val_accuracy: 0.6875\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7448 - val_loss: 0.5565 - val_accuracy: 0.6823\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7431 - val_loss: 0.5564 - val_accuracy: 0.6823\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7431 - val_loss: 0.5564 - val_accuracy: 0.6823\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7465 - val_loss: 0.5564 - val_accuracy: 0.6823\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7465 - val_loss: 0.5563 - val_accuracy: 0.6875\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.7465 - val_loss: 0.5563 - val_accuracy: 0.6875\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7448 - val_loss: 0.5563 - val_accuracy: 0.6875\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7465 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7465 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7448 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7448 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7465 - val_loss: 0.5560 - val_accuracy: 0.6823\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7465 - val_loss: 0.5560 - val_accuracy: 0.6823\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7483 - val_loss: 0.5560 - val_accuracy: 0.6823\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7500 - val_loss: 0.5559 - val_accuracy: 0.6823\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7517 - val_loss: 0.5559 - val_accuracy: 0.6823\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7517 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7500 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7500 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7500 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7500 - val_loss: 0.5557 - val_accuracy: 0.6771\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7483 - val_loss: 0.5557 - val_accuracy: 0.6771\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7465 - val_loss: 0.5556 - val_accuracy: 0.6771\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7483 - val_loss: 0.5556 - val_accuracy: 0.6771\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7483 - val_loss: 0.5555 - val_accuracy: 0.6771\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7465 - val_loss: 0.5555 - val_accuracy: 0.6771\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7465 - val_loss: 0.5555 - val_accuracy: 0.6771\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7465 - val_loss: 0.5554 - val_accuracy: 0.6771\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7465 - val_loss: 0.5554 - val_accuracy: 0.6771\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7483 - val_loss: 0.5554 - val_accuracy: 0.6771\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7483 - val_loss: 0.5553 - val_accuracy: 0.6771\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7483 - val_loss: 0.5553 - val_accuracy: 0.6771\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7465 - val_loss: 0.5552 - val_accuracy: 0.6771\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7465 - val_loss: 0.5552 - val_accuracy: 0.6771\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7448 - val_loss: 0.5552 - val_accuracy: 0.6771\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7465 - val_loss: 0.5551 - val_accuracy: 0.6771\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7465 - val_loss: 0.5551 - val_accuracy: 0.6823\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7465 - val_loss: 0.5551 - val_accuracy: 0.6823\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7465 - val_loss: 0.5550 - val_accuracy: 0.6823\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7431 - val_loss: 0.5550 - val_accuracy: 0.6771\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7431 - val_loss: 0.5549 - val_accuracy: 0.6771\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7431 - val_loss: 0.5549 - val_accuracy: 0.6771\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7431 - val_loss: 0.5549 - val_accuracy: 0.6823\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7431 - val_loss: 0.5548 - val_accuracy: 0.6823\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7431 - val_loss: 0.5548 - val_accuracy: 0.6823\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7431 - val_loss: 0.5548 - val_accuracy: 0.6771\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7431 - val_loss: 0.5547 - val_accuracy: 0.6771\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7431 - val_loss: 0.5547 - val_accuracy: 0.6771\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7431 - val_loss: 0.5546 - val_accuracy: 0.6771\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7413 - val_loss: 0.5546 - val_accuracy: 0.6719\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7413 - val_loss: 0.5545 - val_accuracy: 0.6719\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7413 - val_loss: 0.5545 - val_accuracy: 0.6719\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7396 - val_loss: 0.5545 - val_accuracy: 0.6719\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7396 - val_loss: 0.5544 - val_accuracy: 0.6719\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7413 - val_loss: 0.5544 - val_accuracy: 0.6719\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7396 - val_loss: 0.5543 - val_accuracy: 0.6719\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7396 - val_loss: 0.5543 - val_accuracy: 0.6719\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7396 - val_loss: 0.5543 - val_accuracy: 0.6719\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7396 - val_loss: 0.5542 - val_accuracy: 0.6719\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7396 - val_loss: 0.5542 - val_accuracy: 0.6719\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7396 - val_loss: 0.5542 - val_accuracy: 0.6719\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7413 - val_loss: 0.5541 - val_accuracy: 0.6719\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7413 - val_loss: 0.5541 - val_accuracy: 0.6719\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7413 - val_loss: 0.5541 - val_accuracy: 0.6719\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7448 - val_loss: 0.5540 - val_accuracy: 0.6719\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7448 - val_loss: 0.5540 - val_accuracy: 0.6719\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7448 - val_loss: 0.5539 - val_accuracy: 0.6719\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7465 - val_loss: 0.5539 - val_accuracy: 0.6719\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7465 - val_loss: 0.5539 - val_accuracy: 0.6719\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7465 - val_loss: 0.5538 - val_accuracy: 0.6719\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7483 - val_loss: 0.5538 - val_accuracy: 0.6719\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7483 - val_loss: 0.5538 - val_accuracy: 0.6719\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7483 - val_loss: 0.5537 - val_accuracy: 0.6719\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7483 - val_loss: 0.5537 - val_accuracy: 0.6719\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7483 - val_loss: 0.5536 - val_accuracy: 0.6719\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7465 - val_loss: 0.5536 - val_accuracy: 0.6719\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7465 - val_loss: 0.5536 - val_accuracy: 0.6719\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7483 - val_loss: 0.5535 - val_accuracy: 0.6719\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7483 - val_loss: 0.5535 - val_accuracy: 0.6667\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7483 - val_loss: 0.5534 - val_accuracy: 0.6667\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7483 - val_loss: 0.5534 - val_accuracy: 0.6667\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7500 - val_loss: 0.5534 - val_accuracy: 0.6719\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7500 - val_loss: 0.5533 - val_accuracy: 0.6771\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7483 - val_loss: 0.5533 - val_accuracy: 0.6771\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7500 - val_loss: 0.5532 - val_accuracy: 0.6771\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7500 - val_loss: 0.5532 - val_accuracy: 0.6771\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7500 - val_loss: 0.5532 - val_accuracy: 0.6771\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7500 - val_loss: 0.5531 - val_accuracy: 0.6771\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7500 - val_loss: 0.5531 - val_accuracy: 0.6771\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7500 - val_loss: 0.5530 - val_accuracy: 0.6771\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7483 - val_loss: 0.5530 - val_accuracy: 0.6719\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7500 - val_loss: 0.5530 - val_accuracy: 0.6719\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7500 - val_loss: 0.5529 - val_accuracy: 0.6719\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7483 - val_loss: 0.5529 - val_accuracy: 0.6771\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7465 - val_loss: 0.5529 - val_accuracy: 0.6771\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7465 - val_loss: 0.5528 - val_accuracy: 0.6771\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7465 - val_loss: 0.5528 - val_accuracy: 0.6823\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7465 - val_loss: 0.5527 - val_accuracy: 0.6823\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7465 - val_loss: 0.5527 - val_accuracy: 0.6823\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7448 - val_loss: 0.5527 - val_accuracy: 0.6823\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7465 - val_loss: 0.5526 - val_accuracy: 0.6823\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7483 - val_loss: 0.5526 - val_accuracy: 0.6823\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7483 - val_loss: 0.5525 - val_accuracy: 0.6875\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7483 - val_loss: 0.5525 - val_accuracy: 0.6927\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7483 - val_loss: 0.5525 - val_accuracy: 0.6927\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7483 - val_loss: 0.5524 - val_accuracy: 0.6927\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7500 - val_loss: 0.5524 - val_accuracy: 0.6979\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7500 - val_loss: 0.5523 - val_accuracy: 0.6979\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7517 - val_loss: 0.5523 - val_accuracy: 0.6979\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7517 - val_loss: 0.5522 - val_accuracy: 0.6979\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7517 - val_loss: 0.5522 - val_accuracy: 0.6979\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7517 - val_loss: 0.5521 - val_accuracy: 0.6979\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7535 - val_loss: 0.5521 - val_accuracy: 0.6979\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7517 - val_loss: 0.5520 - val_accuracy: 0.6979\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.7517 - val_loss: 0.5520 - val_accuracy: 0.6979\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7517 - val_loss: 0.5519 - val_accuracy: 0.6979\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7517 - val_loss: 0.5519 - val_accuracy: 0.6979\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7517 - val_loss: 0.5518 - val_accuracy: 0.6979\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7517 - val_loss: 0.5518 - val_accuracy: 0.6979\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7535 - val_loss: 0.5517 - val_accuracy: 0.6979\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7535 - val_loss: 0.5517 - val_accuracy: 0.6979\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7535 - val_loss: 0.5516 - val_accuracy: 0.6979\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7552 - val_loss: 0.5516 - val_accuracy: 0.6979\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7552 - val_loss: 0.5515 - val_accuracy: 0.6979\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7552 - val_loss: 0.5515 - val_accuracy: 0.6979\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7552 - val_loss: 0.5515 - val_accuracy: 0.6979\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7552 - val_loss: 0.5514 - val_accuracy: 0.6979\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7552 - val_loss: 0.5514 - val_accuracy: 0.6979\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7552 - val_loss: 0.5513 - val_accuracy: 0.6979\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7552 - val_loss: 0.5513 - val_accuracy: 0.6979\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7569 - val_loss: 0.5512 - val_accuracy: 0.6979\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7569 - val_loss: 0.5512 - val_accuracy: 0.6979\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7569 - val_loss: 0.5511 - val_accuracy: 0.6979\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7587 - val_loss: 0.5511 - val_accuracy: 0.6979\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7587 - val_loss: 0.5511 - val_accuracy: 0.6979\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7587 - val_loss: 0.5510 - val_accuracy: 0.6979\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7587 - val_loss: 0.5510 - val_accuracy: 0.6979\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7587 - val_loss: 0.5509 - val_accuracy: 0.6979\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7587 - val_loss: 0.5509 - val_accuracy: 0.6979\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7587 - val_loss: 0.5509 - val_accuracy: 0.6979\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7587 - val_loss: 0.5508 - val_accuracy: 0.6979\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7587 - val_loss: 0.5508 - val_accuracy: 0.6979\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7587 - val_loss: 0.5507 - val_accuracy: 0.6979\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7587 - val_loss: 0.5507 - val_accuracy: 0.6979\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7587 - val_loss: 0.5507 - val_accuracy: 0.6979\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7587 - val_loss: 0.5506 - val_accuracy: 0.6979\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7587 - val_loss: 0.5506 - val_accuracy: 0.6979\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7587 - val_loss: 0.5505 - val_accuracy: 0.6979\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7587 - val_loss: 0.5505 - val_accuracy: 0.6979\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7587 - val_loss: 0.5505 - val_accuracy: 0.6979\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7587 - val_loss: 0.5504 - val_accuracy: 0.6979\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7587 - val_loss: 0.5504 - val_accuracy: 0.6979\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7587 - val_loss: 0.5503 - val_accuracy: 0.6979\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7587 - val_loss: 0.5503 - val_accuracy: 0.6979\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7604 - val_loss: 0.5503 - val_accuracy: 0.6979\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7604 - val_loss: 0.5502 - val_accuracy: 0.6979\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7604 - val_loss: 0.5502 - val_accuracy: 0.6979\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7604 - val_loss: 0.5502 - val_accuracy: 0.6979\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7587 - val_loss: 0.5501 - val_accuracy: 0.6979\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.7587 - val_loss: 0.5501 - val_accuracy: 0.7031\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.7587 - val_loss: 0.5500 - val_accuracy: 0.7031\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7587 - val_loss: 0.5500 - val_accuracy: 0.7031\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.7587 - val_loss: 0.5500 - val_accuracy: 0.7031\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.7587 - val_loss: 0.5499 - val_accuracy: 0.7031\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7587 - val_loss: 0.5499 - val_accuracy: 0.7031\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7587 - val_loss: 0.5499 - val_accuracy: 0.7031\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7587 - val_loss: 0.5498 - val_accuracy: 0.7031\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7587 - val_loss: 0.5498 - val_accuracy: 0.7031\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7587 - val_loss: 0.5498 - val_accuracy: 0.7031\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7587 - val_loss: 0.5497 - val_accuracy: 0.7031\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7587 - val_loss: 0.5497 - val_accuracy: 0.7031\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7587 - val_loss: 0.5497 - val_accuracy: 0.7031\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7587 - val_loss: 0.5496 - val_accuracy: 0.6979\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7587 - val_loss: 0.5496 - val_accuracy: 0.6979\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7622 - val_loss: 0.5495 - val_accuracy: 0.6979\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7622 - val_loss: 0.5495 - val_accuracy: 0.6979\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7639 - val_loss: 0.5495 - val_accuracy: 0.6979\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7639 - val_loss: 0.5494 - val_accuracy: 0.6979\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7639 - val_loss: 0.5494 - val_accuracy: 0.6979\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7622 - val_loss: 0.5493 - val_accuracy: 0.6979\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7622 - val_loss: 0.5493 - val_accuracy: 0.6979\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7622 - val_loss: 0.5492 - val_accuracy: 0.6979\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7622 - val_loss: 0.5492 - val_accuracy: 0.6979\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7622 - val_loss: 0.5492 - val_accuracy: 0.6979\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7622 - val_loss: 0.5491 - val_accuracy: 0.6979\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7622 - val_loss: 0.5491 - val_accuracy: 0.6979\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7622 - val_loss: 0.5490 - val_accuracy: 0.6979\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7622 - val_loss: 0.5490 - val_accuracy: 0.6979\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7622 - val_loss: 0.5489 - val_accuracy: 0.6979\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7622 - val_loss: 0.5489 - val_accuracy: 0.6979\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7622 - val_loss: 0.5488 - val_accuracy: 0.6979\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7622 - val_loss: 0.5488 - val_accuracy: 0.6979\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7622 - val_loss: 0.5487 - val_accuracy: 0.6979\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7569 - val_loss: 0.5487 - val_accuracy: 0.7031\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7569 - val_loss: 0.5487 - val_accuracy: 0.7031\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7569 - val_loss: 0.5486 - val_accuracy: 0.7031\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7552 - val_loss: 0.5486 - val_accuracy: 0.7031\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7569 - val_loss: 0.5485 - val_accuracy: 0.7031\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7569 - val_loss: 0.5485 - val_accuracy: 0.7031\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7552 - val_loss: 0.5484 - val_accuracy: 0.7031\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7552 - val_loss: 0.5484 - val_accuracy: 0.7083\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7552 - val_loss: 0.5484 - val_accuracy: 0.7083\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7552 - val_loss: 0.5483 - val_accuracy: 0.7083\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7587 - val_loss: 0.5483 - val_accuracy: 0.7083\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7569 - val_loss: 0.5482 - val_accuracy: 0.7083\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7569 - val_loss: 0.5482 - val_accuracy: 0.7083\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7569 - val_loss: 0.5482 - val_accuracy: 0.7083\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7569 - val_loss: 0.5481 - val_accuracy: 0.7083\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7569 - val_loss: 0.5481 - val_accuracy: 0.7083\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7569 - val_loss: 0.5481 - val_accuracy: 0.7083\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7587 - val_loss: 0.5480 - val_accuracy: 0.7083\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7569 - val_loss: 0.5480 - val_accuracy: 0.7083\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7569 - val_loss: 0.5480 - val_accuracy: 0.7083\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7587 - val_loss: 0.5479 - val_accuracy: 0.7083\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7569 - val_loss: 0.5479 - val_accuracy: 0.7083\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7587 - val_loss: 0.5478 - val_accuracy: 0.7083\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7604 - val_loss: 0.5478 - val_accuracy: 0.7083\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7604 - val_loss: 0.5477 - val_accuracy: 0.7083\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7604 - val_loss: 0.5477 - val_accuracy: 0.7083\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7604 - val_loss: 0.5476 - val_accuracy: 0.7083\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7587 - val_loss: 0.5475 - val_accuracy: 0.7083\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7604 - val_loss: 0.5475 - val_accuracy: 0.7083\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7604 - val_loss: 0.5474 - val_accuracy: 0.7083\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7622 - val_loss: 0.5473 - val_accuracy: 0.7083\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7622 - val_loss: 0.5473 - val_accuracy: 0.7083\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7604 - val_loss: 0.5472 - val_accuracy: 0.7083\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7622 - val_loss: 0.5472 - val_accuracy: 0.7083\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7622 - val_loss: 0.5471 - val_accuracy: 0.7083\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7622 - val_loss: 0.5470 - val_accuracy: 0.7083\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7622 - val_loss: 0.5470 - val_accuracy: 0.7083\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7622 - val_loss: 0.5469 - val_accuracy: 0.7083\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7622 - val_loss: 0.5469 - val_accuracy: 0.7083\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7587 - val_loss: 0.5468 - val_accuracy: 0.7083\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7587 - val_loss: 0.5468 - val_accuracy: 0.7083\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7587 - val_loss: 0.5467 - val_accuracy: 0.7083\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7604 - val_loss: 0.5466 - val_accuracy: 0.7083\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7604 - val_loss: 0.5466 - val_accuracy: 0.7083\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7587 - val_loss: 0.5465 - val_accuracy: 0.7135\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7604 - val_loss: 0.5465 - val_accuracy: 0.7135\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7587 - val_loss: 0.5464 - val_accuracy: 0.7135\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7604 - val_loss: 0.5463 - val_accuracy: 0.7135\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7587 - val_loss: 0.5463 - val_accuracy: 0.7135\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7604 - val_loss: 0.5462 - val_accuracy: 0.7083\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7622 - val_loss: 0.5462 - val_accuracy: 0.7083\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7622 - val_loss: 0.5461 - val_accuracy: 0.7083\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7604 - val_loss: 0.5461 - val_accuracy: 0.7083\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7622 - val_loss: 0.5460 - val_accuracy: 0.7083\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7622 - val_loss: 0.5459 - val_accuracy: 0.7083\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7622 - val_loss: 0.5459 - val_accuracy: 0.7083\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7622 - val_loss: 0.5458 - val_accuracy: 0.7083\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7622 - val_loss: 0.5458 - val_accuracy: 0.7083\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7622 - val_loss: 0.5457 - val_accuracy: 0.7083\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7622 - val_loss: 0.5456 - val_accuracy: 0.7083\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7622 - val_loss: 0.5456 - val_accuracy: 0.7083\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7622 - val_loss: 0.5455 - val_accuracy: 0.7083\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7622 - val_loss: 0.5454 - val_accuracy: 0.7083\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7622 - val_loss: 0.5454 - val_accuracy: 0.7083\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7622 - val_loss: 0.5453 - val_accuracy: 0.7083\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7622 - val_loss: 0.5452 - val_accuracy: 0.7083\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7622 - val_loss: 0.5451 - val_accuracy: 0.7083\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7622 - val_loss: 0.5451 - val_accuracy: 0.7135\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7622 - val_loss: 0.5450 - val_accuracy: 0.7135\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7622 - val_loss: 0.5449 - val_accuracy: 0.7135\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7622 - val_loss: 0.5449 - val_accuracy: 0.7135\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7622 - val_loss: 0.5448 - val_accuracy: 0.7188\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7622 - val_loss: 0.5447 - val_accuracy: 0.7188\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7622 - val_loss: 0.5446 - val_accuracy: 0.7188\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7622 - val_loss: 0.5446 - val_accuracy: 0.7188\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7622 - val_loss: 0.5445 - val_accuracy: 0.7135\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7622 - val_loss: 0.5444 - val_accuracy: 0.7135\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7622 - val_loss: 0.5444 - val_accuracy: 0.7135\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7622 - val_loss: 0.5443 - val_accuracy: 0.7135\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7622 - val_loss: 0.5442 - val_accuracy: 0.7135\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7622 - val_loss: 0.5442 - val_accuracy: 0.7135\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7639 - val_loss: 0.5441 - val_accuracy: 0.7135\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7639 - val_loss: 0.5440 - val_accuracy: 0.7135\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7639 - val_loss: 0.5439 - val_accuracy: 0.7188\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7639 - val_loss: 0.5439 - val_accuracy: 0.7188\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7639 - val_loss: 0.5438 - val_accuracy: 0.7188\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7639 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7639 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7639 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7639 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7639 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7639 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7639 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7639 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7639 - val_loss: 0.5433 - val_accuracy: 0.7240\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7639 - val_loss: 0.5432 - val_accuracy: 0.7240\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7639 - val_loss: 0.5432 - val_accuracy: 0.7188\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7639 - val_loss: 0.5431 - val_accuracy: 0.7188\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7656 - val_loss: 0.5431 - val_accuracy: 0.7188\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7674 - val_loss: 0.5430 - val_accuracy: 0.7188\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7674 - val_loss: 0.5429 - val_accuracy: 0.7188\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7656 - val_loss: 0.5429 - val_accuracy: 0.7188\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7674 - val_loss: 0.5428 - val_accuracy: 0.7188\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7674 - val_loss: 0.5427 - val_accuracy: 0.7188\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.5427 - val_accuracy: 0.7188\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7691 - val_loss: 0.5426 - val_accuracy: 0.7188\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7674 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7674 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7691 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.5421 - val_accuracy: 0.7188\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.5421 - val_accuracy: 0.7188\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7674 - val_loss: 0.5420 - val_accuracy: 0.7188\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7674 - val_loss: 0.5419 - val_accuracy: 0.7188\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7674 - val_loss: 0.5418 - val_accuracy: 0.7188\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7656 - val_loss: 0.5417 - val_accuracy: 0.7188\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7674 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7656 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7639 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7656 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7639 - val_loss: 0.5412 - val_accuracy: 0.7240\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7639 - val_loss: 0.5411 - val_accuracy: 0.7240\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7656 - val_loss: 0.5410 - val_accuracy: 0.7240\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7639 - val_loss: 0.5409 - val_accuracy: 0.7240\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7639 - val_loss: 0.5408 - val_accuracy: 0.7240\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7656 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7639 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7639 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7639 - val_loss: 0.5405 - val_accuracy: 0.7240\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7639 - val_loss: 0.5404 - val_accuracy: 0.7240\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7639 - val_loss: 0.5403 - val_accuracy: 0.7240\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7639 - val_loss: 0.5402 - val_accuracy: 0.7240\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7639 - val_loss: 0.5402 - val_accuracy: 0.7240\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7639 - val_loss: 0.5401 - val_accuracy: 0.7240\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7639 - val_loss: 0.5400 - val_accuracy: 0.7240\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7639 - val_loss: 0.5400 - val_accuracy: 0.7188\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7639 - val_loss: 0.5399 - val_accuracy: 0.7188\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7639 - val_loss: 0.5398 - val_accuracy: 0.7188\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7639 - val_loss: 0.5398 - val_accuracy: 0.7240\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7639 - val_loss: 0.5397 - val_accuracy: 0.7240\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7639 - val_loss: 0.5396 - val_accuracy: 0.7240\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7639 - val_loss: 0.5395 - val_accuracy: 0.7240\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7656 - val_loss: 0.5395 - val_accuracy: 0.7240\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7656 - val_loss: 0.5394 - val_accuracy: 0.7240\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7656 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7656 - val_loss: 0.5393 - val_accuracy: 0.7344\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7656 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7674 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7656 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7656 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7656 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7656 - val_loss: 0.5389 - val_accuracy: 0.7344\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7656 - val_loss: 0.5389 - val_accuracy: 0.7344\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7656 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7639 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7656 - val_loss: 0.5387 - val_accuracy: 0.7344\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7656 - val_loss: 0.5387 - val_accuracy: 0.7344\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7639 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7656 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7656 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7639 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7639 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7639 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7639 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7639 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7639 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7639 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7639 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7656 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7656 - val_loss: 0.5382 - val_accuracy: 0.7396\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7656 - val_loss: 0.5382 - val_accuracy: 0.7396\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7674 - val_loss: 0.5382 - val_accuracy: 0.7396\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7656 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7674 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7674 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7674 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7674 - val_loss: 0.5380 - val_accuracy: 0.7396\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7674 - val_loss: 0.5380 - val_accuracy: 0.7396\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7674 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7674 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7674 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7656 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7656 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7656 - val_loss: 0.5377 - val_accuracy: 0.7396\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7656 - val_loss: 0.5377 - val_accuracy: 0.7396\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7656 - val_loss: 0.5376 - val_accuracy: 0.7396\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7674 - val_loss: 0.5376 - val_accuracy: 0.7396\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7674 - val_loss: 0.5375 - val_accuracy: 0.7396\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7674 - val_loss: 0.5375 - val_accuracy: 0.7396\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7691 - val_loss: 0.5375 - val_accuracy: 0.7396\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7708 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7691 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7691 - val_loss: 0.5373 - val_accuracy: 0.7448\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7691 - val_loss: 0.5373 - val_accuracy: 0.7448\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7691 - val_loss: 0.5372 - val_accuracy: 0.7448\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.5372 - val_accuracy: 0.7448\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7726 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7708 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7726 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.5369 - val_accuracy: 0.7448\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.5369 - val_accuracy: 0.7448\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.5368 - val_accuracy: 0.7448\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.5368 - val_accuracy: 0.7448\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.5368 - val_accuracy: 0.7448\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.5367 - val_accuracy: 0.7448\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7743 - val_loss: 0.5367 - val_accuracy: 0.7448\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7743 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7726 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7726 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7726 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7691 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7726 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7708 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7726 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7708 - val_loss: 0.5363 - val_accuracy: 0.7500\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7708 - val_loss: 0.5363 - val_accuracy: 0.7500\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7691 - val_loss: 0.5363 - val_accuracy: 0.7500\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7691 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7708 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7691 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7691 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7708 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7743 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7743 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7743 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7760 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7778 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7778 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7778 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7778 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7795 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7778 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7795 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7795 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7795 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7795 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7795 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7812 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7795 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7812 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7812 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7812 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7812 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7812 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7812 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7812 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7812 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7812 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7812 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7812 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7812 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7812 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7812 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7812 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7812 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7812 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7830 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7830 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7830 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7830 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7830 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5330 - val_accuracy: 0.7500\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5330 - val_accuracy: 0.7500\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5330 - val_accuracy: 0.7500\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7500\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5329 - val_accuracy: 0.7500\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7500\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5329 - val_accuracy: 0.7500\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7500\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7500\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7500\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7830 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7830 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7830 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7830 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7830 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7830 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7830 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7830 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7812 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7812 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7830 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7830 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7830 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7830 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7830 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7830 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7812 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7812 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7812 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7830 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7830 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.78 - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7865 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7865 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7865 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7865 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7865 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7865 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7865 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7865 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7882 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7882 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7865 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7865 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7882 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7865 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7882 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7865 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7865 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7865 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7882 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7882 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.7830 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5288 - val_accuracy: 0.7344\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5288 - val_accuracy: 0.7344\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5288 - val_accuracy: 0.7344\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5288 - val_accuracy: 0.7344\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7865 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7500\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7500\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7917 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7899 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7899 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7917 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7917 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7899 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7917 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7917 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7917 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8003 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8003 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8003 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8003 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8003 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8021 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8021 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8021 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8003 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8003 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8003 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.8003 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.8021 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.8003 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8003 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8003 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8003 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8003 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.8021 - val_loss: 0.5275 - val_accuracy: 0.7656\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.8021 - val_loss: 0.5275 - val_accuracy: 0.7656\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.8021 - val_loss: 0.5275 - val_accuracy: 0.7656\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.5275 - val_accuracy: 0.7656\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8021 - val_loss: 0.5275 - val_accuracy: 0.7708\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.771\n",
      "roc-auc is 0.812\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
