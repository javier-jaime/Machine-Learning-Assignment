{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Image Classification with TensorFlow on Cloud AI Platform\n",
    "\n",
    "This notebook demonstrates how to implement different image models on MNIST using the [tf.keras API](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras).\n",
    "\n",
    "## Learning Objectives\n",
    "1. Understand how to build a Dense Neural Network (DNN) for image classification\n",
    "2. Understand how to use dropout (DNN) for image classification\n",
    "3. Understand how to use Convolutional Neural Networks (CNN)\n",
    "4. Know how to deploy and use an image classification model using Google Cloud's [AI Platform](https://cloud.google.com/ai-platform/)\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in the notebook, where you will complete the notebook cell's code before running the cell. Refer to the [solution notebook](../solutions/2_mnist_models.ipynb))for reference.\n",
    "\n",
    "First things first. Configure the parameters below to match your own Google Cloud project details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nny3m465gKkY"
   },
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Here we'll show the currently installed version of TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "PROJECT = \"qwiklabs-gcp-03-fa08b4c09c4a\"  # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = \"qwiklabs-gcp-03-fa08b4c09c4a\"  # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = \"us-central1\"  # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "MODEL_TYPE = \"cnn\"  # \"linear\", \"cnn\", \"dnn_dropout\", or \"dnn\"\n",
    "\n",
    "# Do not change these\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"MODEL_TYPE\"] = MODEL_TYPE\n",
    "os.environ[\"TFVERSION\"] = \"2.6\"  # Tensorflow  version\n",
    "os.environ[\"IMAGE_URI\"] = os.path.join(\"gcr.io\", PROJECT, \"mnist_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a dynamic model\n",
    "\n",
    "In the previous notebook, <a href=\"1_mnist_linear.ipynb\">1_mnist_linear.ipynb</a>, we ran our code directly from the notebook. In order to run it on the AI Platform, it needs to be packaged as a python module.\n",
    "\n",
    "The boilerplate structure for this module has already been set up in the folder `mnist_models`. The module lives in the sub-folder, `trainer`, and is designated as a python package with the empty `__init__.py` (`mnist_models/trainer/__init__.py`) file. It still needs the model and a trainer to run it, so let's make them.\n",
    "\n",
    "Let's start with the trainer file first. This file parses command line arguments to feed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mnist_models/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_models/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from . import model\n",
    "\n",
    "\n",
    "def _parse_arguments(argv):\n",
    "    \"\"\"Parses command-line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--model_type',\n",
    "        help='Which model type to use',\n",
    "        type=str, default='linear')\n",
    "    parser.add_argument(\n",
    "        '--epochs',\n",
    "        help='The number of epochs to train',\n",
    "        type=int, default=10)\n",
    "    parser.add_argument(\n",
    "        '--steps_per_epoch',\n",
    "        help='The number of steps per epoch to train',\n",
    "        type=int, default=100)\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help='Directory where to save the given model',\n",
    "        type=str, default='mnist_models/')\n",
    "    return parser.parse_known_args(argv)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Parses command line arguments and kicks off model training.\"\"\"\n",
    "    args = _parse_arguments(sys.argv[1:])[0]\n",
    "\n",
    "    # Configure path for hyperparameter tuning.\n",
    "    trial_id = json.loads(\n",
    "        os.environ.get('TF_CONFIG', '{}')).get('task', {}).get('trial', '')\n",
    "    output_path = args.job_dir if not trial_id else args.job_dir + '/'\n",
    "\n",
    "    model_layers = model.get_layers(args.model_type)\n",
    "    image_model = model.build_model(model_layers, args.job_dir)\n",
    "    model_history = model.train_and_evaluate(\n",
    "        image_model, args.epochs, args.steps_per_epoch, args.job_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's group non-model functions into a util file to keep the model file simple. We'll copy over the `scale` and `load_dataset` functions from the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mnist_models/trainer/util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_models/trainer/util.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def scale(image, label):\n",
    "    \"\"\"Scales images from a 0-255 int range to a 0-1 float range\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "        data, training=True, buffer_size=5000, batch_size=100, nclasses=10):\n",
    "    \"\"\"Loads MNIST dataset into a tf.data.Dataset\"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "    x = x_train if training else x_test\n",
    "    y = y_train if training else y_test\n",
    "    # One-hot encode the classes\n",
    "    y = tf.keras.utils.to_categorical(y, nclasses)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(scale).batch(batch_size)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(buffer_size).repeat()\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's code the models! The [tf.keras API](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras) accepts an array of [layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers) into a [model object](https://www.tensorflow.org/api_docs/python/tf/keras/Model), so we can create a dictionary of layers based on the different model types we want to use. The below file has two functions: `get_layers` and `create_and_train_model`. We will build the structure of our model in `get_layers`. Last but not least, we'll copy over the training code from the previous lab into `train_and_evaluate`.\n",
    "\n",
    "**TODO 1**: Define the Keras layers for a DNN model   \n",
    "**TODO 2**: Define the Keras layers for a dropout model  \n",
    "**TODO 3**: Define the Keras layers for a CNN model  \n",
    "\n",
    "Hint: These models progressively build on each other. Look at the imported `tensorflow.keras.layers` modules and the default values for the variables defined in `get_layers` for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mnist_models/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_models/trainer/model.py\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Softmax)\n",
    "\n",
    "from . import util\n",
    "\n",
    "\n",
    "# Image Variables\n",
    "WIDTH = 28\n",
    "HEIGHT = 28\n",
    "\n",
    "\n",
    "def get_layers(\n",
    "        model_type,\n",
    "        nclasses=10,\n",
    "        hidden_layer_1_neurons=400,\n",
    "        hidden_layer_2_neurons=100,\n",
    "        dropout_rate=0.25,\n",
    "        num_filters_1=64,\n",
    "        kernel_size_1=3,\n",
    "        pooling_size_1=2,\n",
    "        num_filters_2=32,\n",
    "        kernel_size_2=3,\n",
    "        pooling_size_2=2):\n",
    "    \"\"\"Constructs layers for a keras model based on a dict of model types.\"\"\"\n",
    "    model_layers = {\n",
    "        'linear': [\n",
    "            Flatten(),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'dnn': [\n",
    "            # TODO\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'dnn_dropout': [\n",
    "            # TODO\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'cnn': [\n",
    "            # TODO\n",
    "            Conv2D(num_filters_1, kernel_size=kernel_size_1,\n",
    "                   activation='relu', input_shape=(WIDTH, HEIGHT, 1)),\n",
    "            MaxPooling2D(pooling_size_1),\n",
    "            Conv2D(num_filters_2, kernel_size=kernel_size_2,\n",
    "                   activation='relu'),\n",
    "            MaxPooling2D(pooling_size_2),\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ]\n",
    "    }\n",
    "    return model_layers[model_type]\n",
    "\n",
    "\n",
    "def build_model(layers, output_dir):\n",
    "    \"\"\"Compiles keras model for image classification.\"\"\"\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, num_epochs, steps_per_epoch, output_dir):\n",
    "    \"\"\"Compiles keras model and loads data into it for training.\"\"\"\n",
    "    mnist = tf.keras.datasets.mnist.load_data()\n",
    "    train_data = util.load_dataset(mnist)\n",
    "    validation_data = util.load_dataset(mnist, training=False)\n",
    "\n",
    "    callbacks = []\n",
    "    if output_dir:\n",
    "        tensorboard_callback = TensorBoard(log_dir=output_dir)\n",
    "        callbacks = [tensorboard_callback]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=validation_data,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "    if output_dir:\n",
    "        export_path = os.path.join(output_dir, 'keras_export')\n",
    "        model.save(export_path, save_format='tf')\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Training\n",
    "\n",
    "With everything set up, let's run locally to test the code. Some of the previous tests have been copied over into a testing script `mnist_models/trainer/test.py` to make sure the model still passes our previous checks. On `line 13`, you can specify which model types you would like to check. `line 14` and `line 15` has the number of epochs and steps per epoch respectively.\n",
    "\n",
    "Moment of truth! Run the code below to check your models against the unit tests. If you see \"OK\" at the end when it's finished running, congrats! You've passed the tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "2021-11-02 19:03:55.515412: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-11-02 19:03:55.650952: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "..\n",
      "*** Building model for linear ***\n",
      "\n",
      "Epoch 1/10\n",
      "100/100 - 5s - loss: 1.2870 - accuracy: 0.6782 - val_loss: 0.7729 - val_accuracy: 0.8351\n",
      "Epoch 2/10\n",
      "100/100 - 2s - loss: 0.6662 - accuracy: 0.8418 - val_loss: 0.5486 - val_accuracy: 0.8761\n",
      "Epoch 3/10\n",
      "100/100 - 2s - loss: 0.5383 - accuracy: 0.8669 - val_loss: 0.4668 - val_accuracy: 0.8871\n",
      "Epoch 4/10\n",
      "100/100 - 2s - loss: 0.4660 - accuracy: 0.8772 - val_loss: 0.4170 - val_accuracy: 0.8965\n",
      "Epoch 5/10\n",
      "100/100 - 2s - loss: 0.3962 - accuracy: 0.8953 - val_loss: 0.3887 - val_accuracy: 0.9004\n",
      "Epoch 6/10\n",
      "100/100 - 2s - loss: 0.3943 - accuracy: 0.8968 - val_loss: 0.3682 - val_accuracy: 0.9040\n",
      "Epoch 7/10\n",
      "100/100 - 2s - loss: 0.3704 - accuracy: 0.8994 - val_loss: 0.3514 - val_accuracy: 0.9072\n",
      "Epoch 8/10\n",
      "100/100 - 1s - loss: 0.3575 - accuracy: 0.9045 - val_loss: 0.3399 - val_accuracy: 0.9107\n",
      "Epoch 9/10\n",
      "100/100 - 1s - loss: 0.3562 - accuracy: 0.8997 - val_loss: 0.3305 - val_accuracy: 0.9102\n",
      "Epoch 10/10\n",
      "100/100 - 1s - loss: 0.3413 - accuracy: 0.9073 - val_loss: 0.3270 - val_accuracy: 0.9111\n",
      "\n",
      "*** Building model for dnn ***\n",
      "\n",
      "Epoch 1/10\n",
      "100/100 - 5s - loss: 0.5866 - accuracy: 0.8351 - val_loss: 0.2839 - val_accuracy: 0.9172\n",
      "Epoch 2/10\n",
      "100/100 - 2s - loss: 0.2722 - accuracy: 0.9206 - val_loss: 0.2098 - val_accuracy: 0.9379\n",
      "Epoch 3/10\n",
      "100/100 - 1s - loss: 0.1927 - accuracy: 0.9433 - val_loss: 0.1847 - val_accuracy: 0.9436\n",
      "Epoch 4/10\n",
      "100/100 - 1s - loss: 0.1840 - accuracy: 0.9442 - val_loss: 0.1531 - val_accuracy: 0.9535\n",
      "Epoch 5/10\n",
      "100/100 - 2s - loss: 0.1495 - accuracy: 0.9556 - val_loss: 0.1287 - val_accuracy: 0.9612\n",
      "Epoch 6/10\n",
      "100/100 - 2s - loss: 0.1436 - accuracy: 0.9586 - val_loss: 0.1168 - val_accuracy: 0.9640\n",
      "Epoch 7/10\n",
      "100/100 - 2s - loss: 0.0989 - accuracy: 0.9710 - val_loss: 0.1089 - val_accuracy: 0.9675\n",
      "Epoch 8/10\n",
      "100/100 - 1s - loss: 0.1102 - accuracy: 0.9656 - val_loss: 0.1176 - val_accuracy: 0.9649\n",
      "Epoch 9/10\n",
      "100/100 - 2s - loss: 0.0903 - accuracy: 0.9726 - val_loss: 0.0928 - val_accuracy: 0.9721\n",
      "Epoch 10/10\n",
      "100/100 - 2s - loss: 0.0936 - accuracy: 0.9699 - val_loss: 0.0976 - val_accuracy: 0.9684\n",
      "\n",
      "*** Building model for dnn_dropout ***\n",
      "\n",
      "Epoch 1/10\n",
      "100/100 - 5s - loss: 0.6611 - accuracy: 0.7994 - val_loss: 0.2954 - val_accuracy: 0.9120\n",
      "Epoch 2/10\n",
      "100/100 - 1s - loss: 0.3186 - accuracy: 0.9034 - val_loss: 0.2018 - val_accuracy: 0.9422\n",
      "Epoch 3/10\n",
      "100/100 - 2s - loss: 0.2228 - accuracy: 0.9335 - val_loss: 0.1805 - val_accuracy: 0.9442\n",
      "Epoch 4/10\n",
      "100/100 - 2s - loss: 0.1961 - accuracy: 0.9416 - val_loss: 0.1480 - val_accuracy: 0.9559\n",
      "Epoch 5/10\n",
      "100/100 - 2s - loss: 0.1701 - accuracy: 0.9500 - val_loss: 0.1275 - val_accuracy: 0.9606\n",
      "Epoch 6/10\n",
      "100/100 - 1s - loss: 0.1554 - accuracy: 0.9563 - val_loss: 0.1135 - val_accuracy: 0.9660\n",
      "Epoch 7/10\n",
      "100/100 - 2s - loss: 0.1299 - accuracy: 0.9586 - val_loss: 0.1102 - val_accuracy: 0.9659\n",
      "Epoch 8/10\n",
      "100/100 - 2s - loss: 0.1201 - accuracy: 0.9653 - val_loss: 0.0995 - val_accuracy: 0.9692\n",
      "Epoch 9/10\n",
      "100/100 - 2s - loss: 0.1144 - accuracy: 0.9666 - val_loss: 0.0995 - val_accuracy: 0.9690\n",
      "Epoch 10/10\n",
      "100/100 - 2s - loss: 0.1088 - accuracy: 0.9676 - val_loss: 0.0910 - val_accuracy: 0.9709\n",
      "\n",
      "*** Building model for cnn ***\n",
      "\n",
      "Epoch 1/10\n",
      "100/100 - 12s - loss: 0.6885 - accuracy: 0.7826 - val_loss: 0.1808 - val_accuracy: 0.9465\n",
      "Epoch 2/10\n",
      "100/100 - 9s - loss: 0.1819 - accuracy: 0.9448 - val_loss: 0.1077 - val_accuracy: 0.9667\n",
      "Epoch 3/10\n",
      "100/100 - 8s - loss: 0.1387 - accuracy: 0.9583 - val_loss: 0.0818 - val_accuracy: 0.9724\n",
      "Epoch 4/10\n",
      "100/100 - 8s - loss: 0.1057 - accuracy: 0.9676 - val_loss: 0.0687 - val_accuracy: 0.9787\n",
      "Epoch 5/10\n",
      "100/100 - 8s - loss: 0.0853 - accuracy: 0.9730 - val_loss: 0.0598 - val_accuracy: 0.9817\n",
      "Epoch 6/10\n",
      "100/100 - 8s - loss: 0.0893 - accuracy: 0.9737 - val_loss: 0.0557 - val_accuracy: 0.9818\n",
      "Epoch 7/10\n",
      "100/100 - 8s - loss: 0.0745 - accuracy: 0.9782 - val_loss: 0.0412 - val_accuracy: 0.9860\n",
      "Epoch 8/10\n",
      "100/100 - 8s - loss: 0.0574 - accuracy: 0.9840 - val_loss: 0.0440 - val_accuracy: 0.9860\n",
      "Epoch 9/10\n",
      "100/100 - 9s - loss: 0.0643 - accuracy: 0.9820 - val_loss: 0.0456 - val_accuracy: 0.9849\n",
      "Epoch 10/10\n",
      "100/100 - 8s - loss: 0.0657 - accuracy: 0.9807 - val_loss: 0.0385 - val_accuracy: 0.9876\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 152.311s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mnist_models.trainer.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that our models are working as expected, let's run it on the [Google Cloud AI Platform](https://cloud.google.com/ml-engine/docs/). We can run it as a python module locally first using the command line.\n",
    "\n",
    "The below cell transfers some of our variables to the command line as well as create a job directory including a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "model_type = 'cnn' # \"linear\", \"cnn\", \"dnn_dropout\", or \"dnn\"\n",
    "\n",
    "os.environ[\"MODEL_TYPE\"] = model_type\n",
    "os.environ[\"JOB_DIR\"] = \"mnist_models/models/{}_{}/\".format(\n",
    "    model_type, current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below runs the local version of the code. The epochs and steps_per_epoch flag can be changed to run for longer or shorter, as defined in our `mnist_models/trainer/task.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 - 10s - loss: 0.9569 - accuracy: 0.7078 - val_loss: 0.3187 - val_accuracy: 0.9050\n",
      "Epoch 2/5\n",
      "50/50 - 5s - loss: 0.3066 - accuracy: 0.9030 - val_loss: 0.1780 - val_accuracy: 0.9461\n",
      "Epoch 3/5\n",
      "50/50 - 5s - loss: 0.1961 - accuracy: 0.9422 - val_loss: 0.1265 - val_accuracy: 0.9619\n",
      "Epoch 4/5\n",
      "50/50 - 5s - loss: 0.1673 - accuracy: 0.9474 - val_loss: 0.1051 - val_accuracy: 0.9672\n",
      "Epoch 5/5\n",
      "50/50 - 5s - loss: 0.1503 - accuracy: 0.9542 - val_loss: 0.0943 - val_accuracy: 0.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-02 19:07:24.608559: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-11-02 19:07:25.090113: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-02 19:07:25.090162: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-02 19:07:25.091262: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-02 19:07:25.841437: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-02 19:07:29.330836: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-02 19:07:29.330885: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-02 19:07:29.412031: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-02 19:07:29.422424: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-02 19:07:29.439951: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: mnist_models/models/cnn_211102_190721/train/plugins/profile/2021_11_02_19_07_29\n",
      "\n",
      "2021-11-02 19:07:29.445278: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to mnist_models/models/cnn_211102_190721/train/plugins/profile/2021_11_02_19_07_29/tensorflow-2-6-20211102-125023.trace.json.gz\n",
      "2021-11-02 19:07:29.462893: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: mnist_models/models/cnn_211102_190721/train/plugins/profile/2021_11_02_19_07_29\n",
      "\n",
      "2021-11-02 19:07:29.463742: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to mnist_models/models/cnn_211102_190721/train/plugins/profile/2021_11_02_19_07_29/tensorflow-2-6-20211102-125023.memory_profile.json.gz\n",
      "2021-11-02 19:07:29.464227: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: mnist_models/models/cnn_211102_190721/train/plugins/profile/2021_11_02_19_07_29\n",
      "Dumped tool data for xplane.pb to mnist_models/models/cnn_211102_190721/train/plugins/profile/2021_11_02_19_07_29/tensorflow-2-6-20211102-125023.xplane.pb\n",
      "Dumped tool data for overview_page.pb to mnist_models/models/cnn_211102_190721/train/plugins/profile/2021_11_02_19_07_29/tensorflow-2-6-20211102-125023.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to mnist_models/models/cnn_211102_190721/train/plugins/profile/2021_11_02_19_07_29/tensorflow-2-6-20211102-125023.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to mnist_models/models/cnn_211102_190721/train/plugins/profile/2021_11_02_19_07_29/tensorflow-2-6-20211102-125023.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to mnist_models/models/cnn_211102_190721/train/plugins/profile/2021_11_02_19_07_29/tensorflow-2-6-20211102-125023.kernel_stats.pb\n",
      "\n",
      "2021-11-02 19:08:07.381370: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 -m mnist_models.trainer.task \\\n",
    "    --job-dir=$JOB_DIR \\\n",
    "    --epochs=5 \\\n",
    "    --steps_per_epoch=50 \\\n",
    "    --model_type=$MODEL_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the cloud\n",
    "\n",
    "Since we're using an unreleased version of TensorFlow on AI Platform, we can instead use a [Deep Learning Container](https://cloud.google.com/ai-platform/deep-learning-containers/docs/overview) in order to take advantage of libraries and applications not normally packaged with AI Platform. Below is a simple [Dockerlife](https://docs.docker.com/engine/reference/builder/) which copies our code to be used in a TF2 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mnist_models/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_models/Dockerfile\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-cpu\n",
    "COPY mnist_models/trainer /mnist_models/trainer\n",
    "ENTRYPOINT [\"python3\", \"-m\", \"mnist_models.trainer.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below command builds the image and ships it off to Google Cloud so it can be used for AI Platform. When built, it will show up [here](http://console.cloud.google.com/gcr) with the name `mnist_models`. ([Click here](https://console.cloud.google.com/cloud-build) to enable Cloud Build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  5.122MB\n",
      "Step 1/3 : FROM gcr.io/deeplearning-platform-release/tf2-cpu\n",
      "latest: Pulling from deeplearning-platform-release/tf2-cpu\n",
      "\n",
      "\u001b[1B55322776: Pulling fs layer \n",
      "\u001b[1B2ea5e826: Pulling fs layer \n",
      "\u001b[1B17d88127: Pulling fs layer \n",
      "\u001b[1Bc3d8cad5: Pulling fs layer \n",
      "\u001b[1Bb700ef54: Pulling fs layer \n",
      "\u001b[1B15f2d117: Pulling fs layer \n",
      "\u001b[1Bdb856627: Pulling fs layer \n",
      "\u001b[1B3f4ee3ac: Pulling fs layer \n",
      "\u001b[1B8ecaa2ea: Pulling fs layer \n",
      "\u001b[1Bb29acd9f: Pulling fs layer \n",
      "\u001b[1B5d896902: Pulling fs layer \n",
      "\u001b[1B0ec4532f: Pulling fs layer \n",
      "\u001b[1B804d9e1a: Pulling fs layer \n",
      "\u001b[1Beeb36239: Pulling fs layer \n",
      "\u001b[1B7e63bda0: Pulling fs layer \n",
      "\u001b[1Bb3b1a811: Pulling fs layer \n",
      "\u001b[13B700ef54: Waiting fs layer \n",
      "\u001b[1B0f172a6e: Pulling fs layer \n",
      "\u001b[14B5f2d117: Waiting fs layer \n",
      "\u001b[1Bdb70b113: Pull complete 779kB/779kBMBB\u001b[18A\u001b[2K\u001b[20A\u001b[2K\u001b[18A\u001b[2K\u001b[20A\u001b[2K\u001b[18A\u001b[2K\u001b[16A\u001b[2K\u001b[18A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[14A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[18A\u001b[2K\u001b[14A\u001b[2K\u001b[20A\u001b[2K\u001b[18A\u001b[2K\u001b[20A\u001b[2K\u001b[14A\u001b[2K\u001b[17A\u001b[2K\u001b[14A\u001b[2K\u001b[20A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[14A\u001b[2K\u001b[9A\u001b[2K\u001b[14A\u001b[2K\u001b[8A\u001b[2K\u001b[14A\u001b[2K\u001b[7A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[18A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:921859560722191c47e3455c735fc26f5e34f885753375619e66cd936503cdba\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-cpu:latest\n",
      " ---> 22dcd77736a0\n",
      "Step 2/3 : COPY mnist_models/trainer /mnist_models/trainer\n",
      " ---> c1c05ec031f4\n",
      "Step 3/3 : ENTRYPOINT [\"python3\", \"-m\", \"mnist_models.trainer.task\"]\n",
      " ---> Running in 43beee46273f\n",
      "Removing intermediate container 43beee46273f\n",
      " ---> 9bc47fe07ae7\n",
      "Successfully built 9bc47fe07ae7\n",
      "Successfully tagged gcr.io/qwiklabs-gcp-03-fa08b4c09c4a/mnist_models:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -f mnist_models/Dockerfile -t $IMAGE_URI ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/qwiklabs-gcp-03-fa08b4c09c4a/mnist_models]\n",
      "\n",
      "\u001b[1B90f7b0b0: Preparing \n",
      "\u001b[1B372e656f: Preparing \n",
      "\u001b[1B8489e40d: Preparing \n",
      "\u001b[1B8b4b60fc: Preparing \n",
      "\u001b[1B0e05661b: Preparing \n",
      "\u001b[1B70fce652: Preparing \n",
      "\u001b[1B025a771c: Preparing \n",
      "\u001b[1Ba3563b3b: Preparing \n",
      "\u001b[1Bda16d684: Preparing \n",
      "\u001b[1Bd713483b: Preparing \n",
      "\u001b[1Be8fa2c09: Preparing \n",
      "\u001b[1B4a910344: Preparing \n",
      "\u001b[1Bbb085eba: Preparing \n",
      "\u001b[1Bd89cd9fa: Preparing \n",
      "\u001b[1B3db7fc57: Preparing \n",
      "\u001b[1B896a61bf: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B22aa19db: Preparing \n",
      "\u001b[1B95697efb: Preparing \n",
      "\u001b[1B789db36d: Preparing \n",
      "\u001b[2B789db36d: Mounted from deeplearning-platform-release/tf2-cpu \u001b[19A\u001b[2K\u001b[17A\u001b[2K\u001b[20A\u001b[2K\u001b[21A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[11A\u001b[2K\u001b[12A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2Klatest: digest: sha256:5da6aebf4427333fb0574611b347fb99d61e0fbe93c10c772a8b4a46590761c1 size: 4713\n"
     ]
    }
   ],
   "source": [
    "!docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can kickoff the [AI Platform training job](https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training). We can pass in our docker image using the `master-image-uri` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "model_type = 'cnn' # \"linear\", \"cnn\", \"dnn_dropout\", or \"dnn\"\n",
    "\n",
    "os.environ[\"MODEL_TYPE\"] = model_type\n",
    "os.environ[\"JOB_DIR\"] = \"gs://{}/mnist_{}_{}/\".format(\n",
    "    BUCKET, model_type, current_time)\n",
    "os.environ[\"JOB_NAME\"] = \"mnist_{}_{}\".format(\n",
    "    model_type, current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-03-fa08b4c09c4a/mnist_cnn_211102_191409/ us-central1 mnist_cnn_211102_191409\n",
      "jobId: mnist_cnn_211102_191409\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [mnist_cnn_211102_191409] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe mnist_cnn_211102_191409\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs mnist_cnn_211102_191409\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $JOB_DIR $REGION $JOB_NAME\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --region=$REGION \\\n",
    "    --master-image-uri=$IMAGE_URI \\\n",
    "    --scale-tier=BASIC_GPU \\\n",
    "    --job-dir=$JOB_DIR \\\n",
    "    -- \\\n",
    "    --model_type=$MODEL_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Once you have a model you're proud of, let's deploy it! All we need to do is give AI Platform the location of the model. Below uses the keras export path of the previous job, but `${JOB_DIR}keras_export/` can always be changed to a different path.\n",
    "\n",
    "Uncomment the delete commands below if you are getting an \"already exists error\" and want to deploy a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying mnist cnn from gs://qwiklabs-gcp-03-fa08b4c09c4a/mnist_cnn_211102_191409/keras_export/ ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [ai_platform/region].\n",
      "Using endpoint [https://ml.googleapis.com/]\n",
      "ERROR: (gcloud.ai-platform.models.create) Resource in projects [qwiklabs-gcp-03-fa08b4c09c4a] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with the same name already exists.\n",
      "    field: model.name\n",
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......\n",
      "...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"mnist\"\n",
    "MODEL_VERSION=${MODEL_TYPE}\n",
    "MODEL_LOCATION=${JOB_DIR}keras_export/\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#yes | gcloud ai-platform versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#yes | gcloud ai-platform models delete ${MODEL_NAME}\n",
    "gcloud config set ai_platform/region global\n",
    "gcloud ai-platform models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ai-platform versions create ${MODEL_VERSION} \\\n",
    "    --model ${MODEL_NAME} \\\n",
    "    --origin ${MODEL_LOCATION} \\\n",
    "    --framework tensorflow \\\n",
    "    --runtime-version=2.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the model, let's take one of the example images.\n",
    "\n",
    "**TODO 4**: Write a `.json` file with image data to send to an AI Platform deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, codecs\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mnist_models.trainer import util\n",
    "\n",
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "IMGNO = 12\n",
    "\n",
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "test_image = x_test[IMGNO]\n",
    "\n",
    "jsondata = test_image.reshape(HEIGHT, WIDTH, 1).tolist()\n",
    "json.dump(jsondata, codecs.open(\"test.json\", \"w\", encoding = \"utf-8\"))\n",
    "plt.imshow(test_image.reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can send it to the prediction service. The output will have a 1 in the index of the corresponding digit it is predicting. Congrats! You've completed the lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOFTMAX_3\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform predict \\\n",
    "    --model=mnist \\\n",
    "    --version=${MODEL_TYPE} \\\n",
    "    --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
